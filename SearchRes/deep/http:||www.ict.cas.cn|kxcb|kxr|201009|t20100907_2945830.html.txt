http://www.ict.cas.cn/kxcb/kxr/201009/t20100907_2945830.html
<!DOCTYPE html PUBLIC "-//W3C//DTD XHTML 1.0 Transitional//EN" "http://www.w3.org/TR/xhtml1/DTD/xhtml1-transitional.dtd">
一、信息检索评测技术的发展
　　随着计算机的出现与普及，尤其是上世纪90年代互联网蓬勃兴起之后，人们摆脱了信息贫乏的桎梏，进入了一个信息极度丰富的社会。目前，仅Google 能索引到的网页就超过80 亿个，图片超过10 亿张。当信息的来源已不再是问题时，如何快捷准确地获取感兴趣的信息，就成为人们关注的主要问题。但互联网信息天生的异构、分散以及海量等特性对检索技术提出了更高的要求，各种信息检索、过滤、提取技术逐渐成为研究的重点。现在，以Web 搜索引擎为代表的信息检索技术已经取得了很大成功，Google、百度、Yahoo! 等搜索引擎已深入到大家的日常工作和生活之中，成为获取信息不可或缺的工具。
　　目前存在很多基于不同的信息检索技术发展而来的搜索引擎系统，对于同一个用户查询，这些系统返回的结果往往存在差异，由此产生了比较结果的问题。而基于主观使用感受的评价既不客观也不可靠，因此，必须发展出一套客观的评测体系，这种评测不受个别人主观感觉的影响，并且所作出的评价在通常情况下都能成立。在信息检索领域，检索系统的评价一直对系统的研究、设计与发展有显著的影响力。一般来说，这种评测研究的方法具有以下特点：明确的形式化研究任务、公开的训练与测试数据、公开的评测比较。它使得研究之间的比较更加客观，从而让研究者认清各种技术的优劣，起到正确引导研究发展方向的目的。
　　文本检索会议TREC
　　二十世纪九十年代，基于军事和反恐情报处理的需要，美国国防部高级研究计划署（DARPA）提出了TIPSTER 文本处理计划，文本检索会议（Text REtrieval Conference，简称TREC）就是该计划的重要组成部分。1992 年，在美国国防部高级研究与开发机构和DARPA 的资助下，NIST 召开了第一届TREC 会议，以后每年举办一次，到2005 年已举办了14 届。TREC的组织者认为，对不同系统的比较，其意义并不在于要证明某个系统优于其他系统，而是要把更多不同的技术放在一起公开讨论，这对技术的发展有很大好处。于是，TREC 自开办之初，就明确提出了四个目标：
　　1. 以大规模测试集为基础，推动信息检索的研究；
　　2. 通过建立一个开放式的论坛，使与会者交流研究成果与心得，以增进学术界、产业界与政府的交流互通；
　　3. 通过对真实检索环境的模拟与重要改进，加速将实验室研究技术转化为商业产品；
　　4. 开发适当且具有实用性的评价技术，供各界遵循采用。
　　TREC 发展到现在，已经成为备受瞩目的标尺性测试，对信息检索研究领域产生了巨大而深远的影响。今天，在TREC 评测中名列前茅的算法往往成为大家研究的重点，很多商用搜索引擎所采用的核心技术就是那些被TREC 证明成功的算法发展而来的。TREC 论坛成为研究人员互相交流学习的重要途径，很多新的思想和方法正是从这里碰撞产生。TREC 为新的热点研究提供了急需的数据和评价体系，促进了这些技术的快速发展。鉴于TREC 的巨大成功，现在的众多评测，甚至其他研究领域的评测，如跨语言检索评测会议NTCIR、CLEF，机器翻译评测TC-STAR 等，都或多或少受到它的影响。
　　中文信息处理研究起步较晚，上世纪八十年代，还面临着汉字编码、分词等基本问题尚未解决的局面。九十年代，随着这些问题取得突破，中文信息处理技术取得了长足进展。此后，随着中文信息处理数据规模的膨胀以及国内外学术交流的增加，国内研究者逐渐认识到评测对于研究的促进作用。2002 年，黄昌宁教授曾呼吁，“为了推动中文信息处理的发展，让我们拿起评测这个武器，扎扎实实地研究其适用技术……没有统一评测的研究成果，终究不是完全可信的。”同一时期，国内的相关研究机构开始尝试参加TREC 等国际评测，并且相继取得了不错的成绩。但专门针对中文的测试项目的缺位使中文信息处理技术还不能得到有效检验。这种状况得到了国内的研究机构和科研管理部门的重视。经过大量的准备，国内相继召开了多个面向中文信息处理技术的评测会议，其中比较有影响的是863 评测、全国搜索引擎和网上信息挖掘会议（SEWM）等。
　　二、信息检索技术简介
　　为了使读者对信息检索研究的进展有更深的了解，这里我们简单介绍一下信息检索技术的基本原理。信息检索系统流程大致如下图所示：
　　总体上，系统可分为四个部分：1. 数据预处理，2.索引生成，3. 查询处理，4. 检索。下面我们分别对各个部分采用的技术加以介绍。
　　目前检索系统的主要数据来源是Web，格式包括网页、WORD 文档、PDF 文档等，这些格式的数据除了正文内容之外，还有大量的标记信息，因此从多种格式的数据中提取正文和其他所需的信息就成为数据预处理的主要任务。此外，众所周知，中文字符存在多种编码，比如GB2312、BIG5、Unicode（CJK 区），而原始数据集往往包含多种编码，因此要正确地检索到结果必须进行统一编码转换。研究者们对预处理部分要提取哪些信息并没有共识，这与后续处理所需的信息密切相关，一般来说，正文、锚文本和链接地址都是要提取出来的。
　　对原始数据建索引是为了快速定位查询词所在的位置，为了达到这个目的，索引的结构非常关键。目前主流的方法是以词为单位构造倒排文档表，其结构大致如下图所示：
　　每个文档都由一串词组成，而用户输入的查询条件通常是若干关键词，因此如果预先记录这些词出现的位置，那么只要在索引文件中找到这些词，也就找到了包含它们的文档。为了进一步提高查询的速度，在组织索引时还可以采用一些更复杂的方法，比如B树、TRIE 树、哈希表等。这个阶段还需要对预处理之后的文档进行词法分析，这是因为很多语言的文本都不宜直接把正文中的字符串用于建立索引。例如，中文里的词与词之间不存在分隔符，因此必须先进行分词，而英文中的词存在很多变形，比如“compute”就存在“computes”、“computing”、“computed”等多种变形，应先进行词根还原。此外，有些词虽然出现频率很高，但对于查询没有任何帮助，比如“的”、“了”等，就无需放入索引，为此需要预备一个停用词表（stop word list）对这类词进行过滤。
　　用户输入的查询条件可以有多种形式，包括关键词、布尔表达式、自然语言形式的描述语句甚至是文本，但如果把这些输入仅当作关键词去检索，显然不能准确把握用户的真实信息需求。很多系统采用查询扩展来克服这一问题。各种语言中都会存在很多同义词，比如查“计算机”的时候，包含“电脑”的结果也应一并返回，这种情况通常会采用查词典的方法解决。但完全基于词典所能提供的信息有限，而且很多时候并不适宜简单地以同义词替换方法进行扩展，因此很多研究者还采用相关反馈、关联矩阵等方法对查询条件进行深入挖掘。
　　最简单的检索系统只需要按照查询词之间的逻辑关系返回相应的文档就可以了，但这种做法显然不能表达结果与查询之间的深层关系。为了把最符合用户需求的结果显示在前面，还需要利用各种信息对结果进行重排序。目前有两大主流技术用于分析结果和查询的相关性：链接分析和基于内容的计算。许多研究者发现，WWW 上超链结构是个非常丰富和重要的资源，如果能够充分利用的话，可以极大地提高检索结果的质量。基于这种链接分析的思想，Sergey Brin 和Larry Page 在1998 年提出了PageRank 算法，同年J.Kleinberg 提出了HITS 算法，其它一些学者也相继提出了另外的链接分析算法，如SALSA，PHITS，Bayesian等算法。这些算法有的已经在实际的系统中实现和使用，并且取得了良好的效果。而基于内容的计算则沿用传统的文本分类方法，多采用向量空间模型、概率模型等方法来逐一计算用户查询和结果的相似度（相关性）。两者各有优缺点，而且恰好互补。链接分析充分利用了Web 上丰富的链接结构信息，但它很少考虑网页本身的内容，而直观上看，基于内容的计算则较为深入地揭示了查询和结果之间的语义关系，但忽略了不同网页之间的指向关系，因此现在很多系统尝试把两者结合起来，以达到更好的性能。
　　三、信息检索技术研究现状
　　为便于理解评测结果所代表的意义，我们先来介绍一下评测中常用的指标。评测指标直接关系到参评系统的最终评价，指标不合理会导致对系统的评价也不合理，因此规范化的评测会议对于评价指标的选择都是很慎重的。
　　早期常用的评测指标包括准确率（Precision）、召回率（Recall）、F1 值等，其意义如下：
　　显而易见，召回率考察系统找全答案的能力，而准确率考察系统找准答案的能力，两者相辅相成，从两个不同侧面较为全面地反映了系统性能。F1 值是一个把准确率和召回率结合起来的指标。考虑到某些情况下不同系统的准确率和召回率互有高低，不便于直接比较，而使用F1 值就可以更直观地对系统性能进行排序。
　　随着测试集规模的扩大以及人们对评测结果理解的深入，更准确反映系统性能的新评价指标逐渐出现，包括：
　　1. 平均准确率（Mean Average Precision， 即MAP）：单个主题的MAP 是每篇相关文档检索出后的准确率的平均值。主题集合的MAP 是每个主题的MAP 的平均值。MAP 是反映系统在全部相关文档上性能的单值指标。
　　2. R-Precision：单个主题的R-Precision 是检索出R 篇文档时的准确率。其中R 是测试集中与主题相关的文档的数目。主题集合的R-Precision 是每个主题的R-Precision 的平均值。
　　3. P@10：P@10 是系统对于该主题返回的前10个结果的准确率。考虑到用户在查看搜索引擎结果时，往往希望在第一个页面（通常为10 个结果）就找到自己所需的信息，因此设置了这样一个拟人化的指标，P@10 常常能比较有效地反映系统在真实应用环境下所表现的性能。
　　一提及信息检索，大家往往马上会想起Google、yahoo 等搜索引擎公司。可以说，Web 搜索引擎与大家的日常生活最为密切，在某种程度上成了信息检索技术的代称。但作为实用化的系统，搜索引擎一般采用比较成熟的技术，并对稳定性、反映速度、界面等工程化问题更为关注。因此，这些系统并不完全代表信息检索技术的发展水平。但由于人们对于各种粒度的信息获取的需求不断增长，国外的学术界和企业界为此投入了相当大的力量进行前瞻性研究，这方面比较有代表性的机构包括马萨诸塞大学、卡耐基梅隆大学、伦敦城市大学、IBM、微软研究院、滑铁卢大学等。
　　总的来看，早期以Okapi、Smart、查询扩展、相关反馈为代表的内容分析技术，后来以Pagerank、HITS 为代表的链接分析技术，以及近年来的语言模型，都曾在信息检索发展过程中掀起研究热潮，但近年来却少有激动人心的新技术出现。2005 年，TREC 在其总结报告指出现在“信息检索性能已进入平台期”。这表明，与用户无关的传统信息检索技术已相对成熟。这些技术已经被商用搜索引擎广泛应用，并在一定程度上解决了用户在粗粒度（文档级）上的信息获取需求。
　　从TREC 来看，现在的任务设置向高精度、细粒度和大规模三个方向倾斜，比较有代表性的有高精度文档检索任务（HARD）、新信息检测任务（Novelty）、问答任务（QA）、TB 级检索（Terabyte）等。其中前三个任务要求返回的结果不再是简单的一篇篇文档，而是信息片断，而TB 级检索则是把测试集的规模提高到了TB 级，其他不变。从评测结果来看，这些任务已经取得了很大进展。但相对于目前的技术而言，这些任务还是相当困难的，与实用还有一段距离。
　　总的来看，国外主流的Web 检索技术已比较成熟，无论从结果、性能还是稳定性来看，都能提供令人满意的结果，并且已经在人们的日常信息获取中发挥作用。更高精度和更细粒度的检索技术仍处于实验室阶段，但这方面的研究方兴未艾。也许在不远的将来，我们就能看到基于这些新技术的搜索引擎的出现。
　　作为扶持科技发展的重要措施之一，863 国家高技术研究发展计划一直对国内的研究有着重要影响。而规范化评测作为检验系统性能的可信机制，逐渐成为863 关注的重点之一。2003 年，国家863 计划软硬件主题设立了“中文信息处理和智能人机接口技术评测”专项课题，对包括机器翻译、语音识别、信息检索在内的中文信息处理关键技术进行评测。该课题由中国科学院计算技术研究所承办，从2003 年到2005年连续举办三届，吸引了国内外众多研究单位参加。信息检索评测的目的并不仅仅定位为863 课题验收或资格认证，而是要了解国内在中文信息检索技术领域的研究现状，验证互联网环境下大规模数据的中文信息检索技术的系统有效性，推动技术进步和成果的应用和转化，成为这个领域技术评价和交流的平台。
　　作为国内有较大影响的评测会议，863 信息检索评测基本上反映了中文信息检索技术的发展水平。下面我们通过2005 年度最新评测结果来分析国内的研究现状。这次评测分为自动和手工构造查询条件两组。评测结果如下表所示（由于863 评测结果发布采用匿名方式，因此这里只给出最终结果而不显示参赛单位名称）：
　　从所有参评队伍的整体检索效果看，这次评测的结果与以往的评测结果相比，各个指标都有了很大提高。这主要是因为研究者利用了链接分析技术、锚文本等相关评价因素来提高准确率，并针对评测采取有效的技术手段来克服中文检索中的某些难点，比如命名实体识别等。此外，相关反馈或者重排序技术对于提高检索效果也有一定的帮助。从检索模型来说，参评队伍采用了向量空间模型、概率模型、语言模型等基本模型或者混合模型，同时利用了PageRank、链入分析等链接分析或者页面分析技术来提高检索效果。中文检索相对英文等其它语种来说，如何正确分词对于检索效果有所影响，尤其是命名实体、缩略语以及新词等未登录词的正确识别对于某些查询来说影响较大。现在的大部分检索系统在索引以及查询分析阶段采用了命名体识别，从结果来看，取得了比较好的效果。
　　当前的中文检索技术均基于国际主流的算法，在评测中成绩较好的单位在TREC 评测中也曾取得不错的成绩。可以看出，这些算法提供了基准级的性能，系统级的创新或改进不多，不过现有系统都会针对中文的特点进行改进。总体上，如果用户草拟的查询条件能够比较全面准确地表达用户需求的话，现有的中文检索技术一般能够提供比较好的检索结果，但是对于以下方面还存在着一些问题：
　　▲ 查询条件与文档词汇内容失配；
　　▲ 部分命名体、新词以及缩略语识别还存在着一些问题；
　　▲ 在计算相似度时，查询词汇权重的设定正确与否也在一定程度上影响检索效果。
　　这些问题的存在导致现有检索系统性能下降，针对这些问题，现有的检索技术还有很大的改善空间来获得比较满意的检索结果。
　　经过众多研究者的努力，规范化评测对信息检索技术发展的重要作用已经得到了广泛认同。虽然和国外相比起步较晚，但短短几年间，中文信息检索的规范化评测从无到有，已经取得了令人鼓舞的进步。但是，总的来说，国内仍处于学习国外的相关评测（尤其是TREC 系列会议）的阶段。
　　规范化评测与公正客观这个终极目标还有一定的距离，而如何降低人为因素的影响仍是摆在评测组织者面前的一道难题。而国内的信息检索评测无论是从数据规模还是从评测手段来看，与国际知名评测仍有较大差距，这是由我国目前的科研和应用的总体水平决定的。但差距的存在也表明提升的空间巨大，国内的相关研究者任重而道远。

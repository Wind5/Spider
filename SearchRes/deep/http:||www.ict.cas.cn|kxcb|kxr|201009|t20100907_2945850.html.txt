http://www.ict.cas.cn/kxcb/kxr/201009/t20100907_2945850.html
<!DOCTYPE html PUBLIC "-//W3C//DTD XHTML 1.0 Transitional//EN" "http://www.w3.org/TR/xhtml1/DTD/xhtml1-transitional.dtd">
一、虚拟化存储技术的现状和挑战
　　虚拟化技术是当前比较热的一个研究领域，也有许多比较成熟的各种虚拟机或模拟器等技术和产品，其中虚拟机的存储管理（Storage Management）是一个很重要的方面，但是往往容易被忽视，尤其是在非单机的环境下。
虚拟机中的虚拟存储广义上也属于一种存储虚拟化（Storage Virtualization），存储虚拟化也是虚拟化技术的一种，近年来也是一个研究的热点，这方面有许多的研究和工作。本文中的存储虚拟化特指虚拟机中的虚拟存储设备，它有着不同于一般存储虚拟化的特性。虚拟机对虚拟存储设备的访问最终经过虚拟机监视器（Virtual Machine Monitor, VMM）映射到实际的物理存储设备上，通常都是虚拟机把IO请求发送给VMM，由VMM直接与实际的存储设备驱动打交道。例如在Xen中，GuestOS都是通过前端驱动与Domain 0上的后端驱动通信，读写虚拟存储设备。虚拟存储设备由Domain 0负责创建和赋给其它Domain，如图1。
为虚拟机提供的虚拟存储设备可以有以下几种方式：
　　1.物理硬盘或其分区，包括iSCSI磁盘或GNBD卷。这种方式的优点是很简单，可以直接将虚拟机的硬盘设置为某个硬盘或分区，不需要再在硬盘分区上另组织成别的形式。但它的缺点是不够灵活，不能够随着虚拟机的需要动态地改变存储空间容量大小，也仅仅适合单机环境，不能够满足大规模系统中设备共享的要求。
　　2.网络存储协议，包括NFS等网络或并行文件系统。这种方式适合于一些使用NFS等的网络存储设备，它的缺点是性能（数据都需要通过网络）和稳定性不高（与网络存储设备有关），而且也不通用，不适合分布式的存储架构。
　　3.基于文件的虚拟存储设备，也称为虚拟磁盘镜像（Virtual Disk Image）。这种方式的优点是配置灵活，而且要启动一个虚拟机必须要有一定形式的虚拟磁盘镜像文件。在Xen 3.0.3以前就可以由loopback驱动配置.img镜像文件作为虚拟机的块设备，3.0.3之后加入了blktap驱动模块，加强了对这方面的支持，目前正积极地进行着对.qcow镜像格式（QEMU中实现的一种镜像文件格式，支持copy-on-write等操作）的支持。其它的镜像文件格式有VMware实现的.vmdk格式，微软在其Virtual PC和Virtual Server中使用的.vhd格式（支持虚拟镜像文件大小的动态伸缩）等等。
　　4.基于逻辑卷。这种方式应该是最好的，因为它同时具有第一种和第三种方式的优点，可以动态地增减容量的大小，支持snapshot、条带化提高IO并行性能等等属性，也可以很方便地进行copy-on-write等操作。
　　目前逻辑卷管理工具主要有EVMS（Enterprise Volume Management System, 企业级卷管理系统）、VxVM（VERITAS Volume Manager , VERITAS卷管理器）、HP-LVM、LVM（Logical Volume Manager, 逻辑卷管理器）。EVMS基于层次和插件结构，功能比较强大，但系统内核并不支持，目前仅仅用于一些大的有特殊功能需求的系统，而且安装起来过于麻烦，它的许多功能并不是每个系统都需要的，灵活性不强；VxVM和HP-LVM的问题都是只配置在特定的系统上，可移植性不强，但有些功能，比如它们提供的用于性能保障的vol_default_iodelay参数（可以用于扼杀过载的IO请求）等等，非常吸引人。LVM是Linux 2.6内核中自带的方便灵活的卷管理工具，它的结构如图2。LVM主要涉及三个概念：物理卷（Physical Volume）、卷组（Volume Group）、逻辑卷（Logical Volume）。LVM首先将各物理分区，包括磁盘阵列等形式，构建成物理卷，主要是配置区块大小、起始位置等工作；然后把各物理卷都加到一个大的卷组里面，主要是配置物理卷名、物理卷属性信息等工作；最后可以从卷组中分配物理区块构成逻辑卷，分配信息会写到卷组的头部，可以在其上部署文件系统，提供给上层应用和虚拟机使用。
　　这样，从虚拟机开始，对数据的访问通路就清晰了，如图3所示。首先虚拟机的IO请求会通过VMM进行处理（这部分具体细节如图1），对文件的请求会通过逻辑卷上的文件系统和逻辑卷的配置信息转换成对相应的逻辑区块的请求；然后由卷管理系统将其转换成对相应的物理区块的请求；再转换成对真实物理设备中对应部分扇区的请求；最后通过驱动程序发出真实的操作命令。
　　把这个图与图1结合起来会发现，由虚拟机的应用出发，IO请求在访问到实际的数据之前经过了许多层级，那么是否可以压缩一些呢？数据应该如何组织和管理才能更好地更高效地提供给虚拟机应用？这也是我们需要研究的一个方面。
　　上面都是在单机中的虚拟机访问虚拟磁盘的方式，那么考虑在大规模的分布式环境下，每个节点都带有各自的存储设备（如图4），都运行着若干个虚拟机，虚拟机可以在全系统范围内动态地迁移，这种情况下，虚拟磁盘的管理都需要做哪些方面的工作。注意这种情况下不要与网络存储混为一谈，首先，我们考虑的是一般的分布式系统，如上所述，这个系统中不存在大的网络存储设备。其次，一般的网络存储系统（例如SAN设备）非常昂贵，而且像我们所关注的系统，节点都是普通的系统，每个节点使用的也都是普通的磁盘，那么建立一个系统把这些磁盘集成起来更为合理。同时，系统级的磁盘集合可以由每个节点上的相互隔离的虚拟机直接控制，而虚拟机直接控制网络存储设备有着许多安全上的问题。另外，我们考虑的系统规模非常庞大。所有这些都说明，SAN等网络存储设备并不适合大的分布式系统中每个节点都运行一定数目的虚拟机的情况。
　　在单机环境下，某个虚拟机的存储空间不足时，我们希望可以通过逻辑卷管理系统向其它节点“借用”一部分存储空间，实现存储资源的“流动”；同样，在多机环境下，我们也希望某个节点的存储资源不足时，可以“借用”其它节点的存储资源，做到全系统范围内存储资源的动态“流动”。
　　要做到存储资源的“流动”，首先要解决存储资源由哪里“流”向哪里、以及“流动”多少的问题。为此，需要建立一套存储设备的性能模型，用于记录每个设备的使用情况，预测将来一定时间内的使用情况，判断哪些设备可以提供空闲的空间共享给其它资源不足的设备，等等。

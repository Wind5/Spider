http://www.ict.cas.cn/xwzx/jssxw/201110/t20111020_3378766.html
<!DOCTYPE html PUBLIC "-//W3C//DTD XHTML 1.0 Transitional//EN" "http://www.w3.org/TR/xhtml1/DTD/xhtml1-transitional.dtd">
大规模数据计算领域技术盛会-Hadoop in China 2011即将在京召开----中国科学院计算技术研究所
由中科院计算所主办的Hadoop中国2011云计算大会（Hadoop in China 2011，HiC2011）将于12月2日至3日在北京会议中心召开，这将是Hadoop in China社区的一次年度技术盛会！大会将联合国际和国内Hadoop及云计算技术应用的成功企业，并引入国际研究界对于云计算及DISC（Data Intensive Super Computing）研究方向的学术观点。通过技术应用和科学研究双重视角审视云计算技术及Hadoop开源生态系统的现状和发展趋势。大会特别邀请了Condor的创始人University of Wisconsin–Madison的Miron Livny教授、以及来自Google、Facebook等国内外著名互联网公司和IT企业的学者和资深开发人员到场演讲并进行技术交流，部分专家是首次来中国访问。
近几年来，越来越多的国内外互联网公司和传统企业都已意识到数据资产规模化带来的潜在价值。以Hadoop为代表的大规模数据处理（Big Data Processing）技术的日趋成熟使得“业务为王”向“数据为王”转变。如淘宝公司的“数据魔方”应用，基于全网交易数据的分析和挖掘，向用户提供行业动态热点和市场发展趋势的深度数据服务。大规模数据处理技术的发展往往超出想象。拿已有6亿用户的Facebook为例，大规模数据处理更向着实时化迈进，其ETL（Extract, Transform, Load）延迟从原来的24到48小时演进到小于10秒，以满足在线和实时数据分析的需求。可以看出“如果性能不满足需求就是功能缺失”这样的系统设计指导思想。此外，规模化的数据如果没有合适的“掘宝工具”是无法体现其价值的。信息检索、内容挖掘、自然语言理解、数据可视化、计算广告学、地理信息系统等领域均采用Hadoop技术研究和开发从数据到价值的各类工具，起到了“海量数据掘宝”的作用。
Hadoop社区的繁荣有目共睹。越来越多的国内外公司参与到Hadoop社区开发，或者直接将线上使用的软件开源。这极大地促进了Hadoop技术在国内的推广发展，扩大了大规模数据处理的应 用范围。我们欣喜地看到，学界对Hadoop的研究热情不减，今年的VLDB上就出现了数篇与MapReduce/Hadoop相关的论文。这说明 Hadoop还有很多可完善可改进的地方。另一方面，一些商业软件也在向Hadoop技术靠拢，兼容Hadoop软件栈。同时，国内外出现了一批以提供 Hadoop技术咨询和服务的公司，Hadoop大规模数据处理技术的商业价值逐渐得到业界的重视。
Hadoop in China大会已历经四届，今年的大会主题是“海量数据掘宝”。希望以“最细致的研发细节，最直接的交流互动”使此次大会达到“理解实际需求，聆听大师观点，促进应用实践，发扬开源精神”的目的。主办方将继承之前几届的办会宗旨，发扬开源精神，不遗余力地促进Hadoop及云计算开源生态系统在国内的发展壮大。

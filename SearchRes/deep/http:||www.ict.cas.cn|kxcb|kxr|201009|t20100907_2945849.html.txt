http://www.ict.cas.cn/kxcb/kxr/201009/t20100907_2945849.html
<!DOCTYPE html PUBLIC "-//W3C//DTD XHTML 1.0 Transitional//EN" "http://www.w3.org/TR/xhtml1/DTD/xhtml1-transitional.dtd">
视频是集图像、声音、文字等为一体的综合性媒体。随着互联网技术的发展和网络带宽的提升，网络视频数据量成爆炸式增长，如何对互联网上的海量视频数据进行搜索已成为国内外的研究热点，是新一代搜索引擎的主要研究内容。
　　视频搜索是通过对海量的非结构化的视频数据进行结构化分析，提取视频内容的特征（包含语义特征），在此基础上实现从内容上对视频进行检索。与传统文本搜索相比，视频搜索存在很大的技术难度。首先，视频内容的特征难以提取与处理，特别是语义特征的提取存在很大的困难。其次，视频搜索在索引建立、查询处理以及人机交互等方面都与传统的文本搜索存在很大区别，还有一些技术难题有待解决。
　　一、视频结构化分析
　　视频结构化分析是指对视频流进行镜头分割、关键帧提取和场景分割等处理，从而得到视频的结构化信息。
　　镜头分割的关键在于确定镜头的边界，其中渐变镜头边界的检测目前仍然是一个具有挑战性的课题。现有镜头分割方法多以视频内容的不连续性为划分镜头的依据。研究者们通常选取视频的某种特征来度量视频内容的不连续性，如颜色特征、运动矢量特征、边缘特征等。
　　由于同一个镜头中的各帧图像之间的内容有相当程度的冗余，因此可以选取反映镜头中主要信息内容的帧图像作为关键帧。镜头分割后，对每个镜头可提取若干关键帧，并用关键帧来简洁地表示镜头。
　　场景分割通常也称为故事单元分割，其目标在于获取视频的最小语义结构单元——场景。一般而言，场景是由一组连续的、同属于一个故事单元的多个镜头组成。通过融合视频的文本、声音等信息对已分割出的镜头进行聚类，将内容相近的连续镜头合并为一个单元组，从而得到场景信息，为进一步进行视频内容分析提供基础。
　　特征提取是进行视频搜索的基础，要实现有效查询，就必须对视频信息进行建模和表示，实际上就是分析视频数据，提取描述特征。一般说来，主要提取以下特征：
　　视觉特征：主要包括视频帧图像的颜色、纹理、形状、运动等低层视觉特征。其中，David G. Low于1999年提出了一种对图像缩放、旋转和仿射变换保持不变的图像局部特征描述算子——SIFT（Scale Invariant Feature Transform）算子，在图像和视频检索中越来越受到人们的重视。
　　听觉特征：听觉特征反映了视频中音频的频谱分布和变化规律、节奏、韵律等，主要包括：短时能量、MFCC系数、基音频率、分带短时能量、短时能量的均值和方差、MFCC系数的均值和协方差、过零率的均值和方差等。
　　文本特征：作为视频高层语义的一种，视频字幕、视频语音、以及互联网Web中的相关文本信息是不必通过语义推理的视频高层语义内容，它对视频内容有很强的描述作用，因而对视频的高层语义分析具有很重要的价值。主要包括以下：
　　ASR文本：视频中一般总是伴随着人说话的声音，我们称这种声音为语音。利用自动语音识别技术，我们可以将语音转换为文本信息。在特定的视频中，反映主题的并且检索频率较高的语音词汇往往在视频局部多次重复出现，即使语音识别引擎不能每次都正确识别，但只要识别一两个实例，也能迅速定位所需要的视频片段。
　　字幕文本：视频帧中出现的文字，特别是后期编辑叠加的文本字幕，经常包含了重要的语义信息，如新闻视频中的主题、日期和人名，以及电影视频中的演员表等。最后利用面向视频的文字识别技术（Video OCR）检测与识别视频中的文本信息。
　　Web文本：在Web 页面中，常有一些与视频相关的外部文本信息，如与新闻视频相关的讲稿或文字报导、与足球比赛相关的文字直播或比赛战况播报等等。通过对Web 页面中文本和视频的空间相关性等信息进行挖掘和融合，通常能获得与当前视频相关的语
　　基于以上文本特征，借助领域相关的命名实体词典和相关知识库，可提取包含时间、地点、人物以及描述事件的关键词等信息，以支持特定时间、地点、人物以及事件的检索。
　　其它特征：如视频中是否存在人脸，以及摄像机的运动特征等。人脸是视频中常见对象，并且蕴涵了丰富的语义信息。
　　三、语义概念（高级语义特征）提取
　　多媒体信息检索已经有数十年的历史，最初的多媒体检索是人对多媒体信息进行手工文字标注，然后通过一般文本检索技术来实现多媒体检索。后来，人们提出通过媒体的低层特征（如帧图像的颜色、纹理、形状、视频的运动特征）对多媒体信息进行基于内容的检索。实际上，人们经常在日常生活中习惯使用诸如“飞机、建筑、天空、海滩、日出、花草树木、轮船”等概念，因而往往希望能够进行基于语义的查询，这就需要利用多媒体数据的高层语义信息。如何建立视频的低层特征和高层语义描述之间的映射，有效克服所谓的“语义鸿沟”，是一直以来困扰科研人员的技术难点，也是当前的一个研究热点。
　　虽然目前从事视频语义概念提取技术研究的单位很多，出现了众多各具特色的系统方案。但就整体而言，这些系统大多由特征提取、分类器模型、融合算法和上下文关联分析这四部分组成。
　　视频语义概念提取所用的特征主要来自如前所述的视觉、听觉、文本等特征，我们需要根据它们各自的特点选用合适的分类器模型。另外，因为视频语义概念大多都具有正样本数少、相关性强的特点，这对分类器模型的使用提出了更高的要求。通常采用的分类器模型有三类：一类是直接将各种全局或局部的特征组成特征向量，利用通用的分类器算法，如SVM、GMM、最大熵、KNN等进行语义概念的检测；另一类是考虑特征之间的时间/空间关联，利用隐马模型进行建模；还有一类模型，将局部特征聚类形成中间分组，在对测试序列求得分组标注后，利用全局的分组直方图进行分类。
　　也可单独从视频文本中直接提取出反映高层语义的概念。由于视频文本通常不准确，不完整，甚至有很多错误（如ASR带来的识别错误，字幕文字识别错误），因此很难用自然语言理解的方法来分析视频文本中的语义。目前大多采用各种统计的方法，如N-Gram文法和隐性语义索引（LSI，Latent Semantic Indexing）等，分析已经存在的大规模语料库，从中学习相关规则，然后用这些规则来推断可能包含的语义。
　　为获得对视频更全面准确的理解，我们需要融合各个模态的信息。信息的融合大致可以分为两个层次：第一个层次为同一模态内的不同特征之间的信息融合；第二个层次为不同模态间的信息融合。两种层次的融合方法是统一的，分为非启发式的融合方法和启发式的融合方法。非启发式的融合方法主要包括：平均加权、取最大值、取最小值、乘积等各种融合方法。非启发式的融合方法的主要优点是不需要对融合方法进行训练，应用简单，鲁棒性较强，但是融合效果一般。启发式的融合方法主要包括：Adaboost方法、加权融合方法（Weighted Average）、基于排序的加权融合方法（Ordered Weighted Average）。启发式的融合方法针对不同的数据进行融合参数的训练，融合效果较好，但是鲁棒性稍差，计算复杂度也要比非启发式融合方法大很多。
　　不同的语义概念之间往往存在一些上下文（Context）约束或者共生关系。比如检测到“天空”和“绿地”会增加检测到“风景”的概率，而减少检测到“室内”的概率。如果仅建立一组单独的概念检测算法，则无法充分利用这些信息。因此，还需要进行上下文关联分析，利用不同概念之间的相互关系，进一步改进概念检测的结果。上下文关联分析算法主要有MultiNets、SVM判别融合方法，以及基于本体论的方法等。
　　从视频中提取特征之后，帧图像被映射为高维特征空间中的样本点。对于海量数据而言，如何建立有效的索引结构，是加快检索速度、提高检索精度的关键问题。同时，由于特征的维数很高，常用的索引方法难以满足需要，具有动态性、高效性、鲁棒性的高维索引结构已成为热门的研究方向。
　　常用的高维索引是树型空间索引，目前普遍采用R*树作为索引的数据结构。针对R树结构受数据输入次序影响的问题，R*树采用强制重新插入策略，对树中已有节点中的单元进行有选择的重新插入，优化树的整体结构，有助于提高查询性能。其代价仅稍高于R树，同时支持点数据和其它空间数据的索引建立与查询。
　　大部分树型空间索引在低维空间中性能优越，但在高维空间中，性能显著下降，这是因为一些重要的参数，如体积、面积等，都与空间维数呈幂级增长的关系。因此，应对高维特征进行降维处理，常用的方法有主成分分析和聚类等方法。
　　五、查询处理与相关反馈
　　查询处理是指处理用户查询的需求，将之转换为可以执行检索的特征向量，以便与索引结构相匹配。用户提交的查询一般是对查询内容的简洁描述，在检索过程中需要对其进行扩展。扩展方法主要有基于规则的扩展和基于统计的扩展。前者利用现有的词典，如HowNet、WordNet、同义词林等查找语义上与该查询相似的词，对其赋予一定的权重后加入查询中。后者统计大规模预料库中与查询词共现最多的词，作为相关词加入到新的查询中。
　　在交互式搜索（Interactive Search）系统中，还需要处理用户的反馈信息，从而调整查询算法，以期获得更加符合用户意愿的查询结果。
　　相关反馈是指根据用户对于检索结果的反馈，其中既包括检索正确的正反馈，也包括检索错误的负反馈（有的系统返回的是用户对检索结果是否正确的置信度），对查询处理结果做适当的调整，如增加产生正反馈的权重，降低导致负反馈的权重等。相关反馈技术是一种有效的交互手段，已经被越来越多的搜索引擎所采用。好的相关反馈算法可以普遍提高检索结果精度，使用户能快速检索到自己需要的结果。另外，由于不同的用户反馈反映了不同用户的偏好，因而相关反馈有利于实现用户的个性化搜索。
　　六、多模态人机界面
　　多模态人机界面涉及多模态方式输入用户界面和输出界面，是系统中必不可少的非常关键的组成部分。用户通过多模态的人机界面与系统交互：输入查询、输出结果或对结果进行反馈。
　　在实际应用中，很多用户对于某些语义概念的掌握程度可能不足以明确表达其查询意愿。如果系统允许用户以多模态的描述方式，比如提交一段文本、一幅或多幅样例图像、一段或多段样例视频片段、一段语音等，来输入查询意愿，那么系统将搜索到更多符合用户要求的查询结果。
　　系统的输出也是一个多模态表示的结果，如关于视频数据的描述信息、一系列相关的图像、一组相关的镜头等等。为全面反映结果的内容，便于用户快速抓住感兴趣的结果和进行更有效的反馈和评价，通常对结果进行层次化组织，并以可视化方式输出。例如，可用“故事板”方式将一些关键帧图像在窗口中平铺，通过点击关键帧图像，用户便可浏览相应的镜头内容。
　　视频语义检索可以通过前述的语义概念提取实现，主要包括从文本或视觉等多模态特征中提取相应的语义概念。其典型算法如图2所示。
　　首先，对于一个特定的查询，需要将该查询转换到语义概念空间。对于文本查询，可以通过词典或相关Web文本进行扩展，确定查询在语义概念空间的坐标；对关键帧样例查询，可以通过NDK（Near Duplicate Keyframes）等方法进行扩展，从中提取语义信息。
　　然后，将检索分为两层：故事单元层和镜头层，分别利用多模态低层特征和高级语义特征（语义概念）进行检索。
　　最后，通过伪相关反馈（Pseudo Relevance Feedback）进一步提高检索精度，即根据前一次检索的结果，自动选取前几项作为正样本，返回给系统进行第二次查询，整个过程不需要用户参与而自动执行，因而称为伪相关反馈。

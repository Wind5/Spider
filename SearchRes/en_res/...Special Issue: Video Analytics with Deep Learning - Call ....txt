 CiteScore measures the average citations received per document published in this title. CiteScore values are based on citation counts in a given year (e.g. 2015) to documents published in three previous calendar years (e.g. 2012 – 14), divided by the number of documents in these three previous years (e.g. 2012 – 14).
 2016: 4.582The Impact Factor measures the average number of citations received in a particular year by papers published in the journal during the two preceding years.
 2016: 4.991To calculate the five year Impact Factor, citations are counted in 2016 to the previous five years and divided by the source items published in the previous five years.
 2016: 1.699SJR is a prestige metric based on the idea that not all citations are the same. SJR uses a similar algorithm as the Google page rank; it provides a quantitative and a qualitative measure of the journal’s impact.
 This application lets readers explore data and other quantitative results submitted with the article, providing insights into and access to data that is otherwise buried in plots.
 Publishing your article with us has many benefits, such as having access to a personal dashboard: citation and usage data on your publications in one place. This free service is available to anyone who has published and whose publication is in Scopus.
We are living in a world where we are surrounded by so many intelligent video-capturing devices.  These devices capture data about how we live and what we do.  For example, thanks to surveillance and action cameras, as well as smart phones and even old-fashioned camcorders, we are able to record videos at an unprecedented scale and pace. There is exceedingly rich information and knowledge embedded in all those videos. With the recent advances in computer vision, we now have the ability to mine such massive visual data to obtain valuable insight about what is happening in the world.  Due to the remarkable successes of deep learning techniques, we are now able to boost video analysis performance significantly and initiate new research directions to analyze video content. For example, convolutional neural networks have demonstrated superiority on modeling high-level visual concepts, while recurrent neural networks have shown promise in modeling temporal dynamics in videos. Deep video analytics, or video analytics with deep learning, is becoming an emerging research area in the field of pattern recognition.
The goal of this special issue is to call for a coordinated effort to understand the opportunities and challenges emerging in video analysis with deep learning techniques, identify key tasks and evaluate the state of the art, showcase innovative methodologies and ideas, introduce large scale real systems or applications, as well as propose new real-world datasets and discuss future directions. The video data of interest cover a wide spectrum, ranging from first-person wearable videos, web videos (aka user-generated content), commercial video programs, to surveillance videos. Video analytics plays an important role in public security, entertainment, healthcare, and so on. We solicit manuscripts in all fields of video analytics that explore the synergy of video understanding and deep learning techniques.
We believe the special issue will offer a timely collection of research updates to benefit the researchers and practitioners working in the broad computer vision and pattern recognition communities. To this end, we solicit original research and survey papers addressing the topics listed below (but not limited to):
First-person/wearable video analysis using deep learning techniques, including object detection and recognition, highlight detection, action recognition, event detection, segmentation and tracking, classification, summarization and storytelling, editing, data collection and benchmarking, and so on.
Video and language  describing video with natural language using deep learning techniques.
Web video understanding using deep learning techniques, including classification, annotation, event detection and recognition, authoring and editing, and summarization.
Home/public video surveillance using deep learning, including motion detection and classification, scene understanding, event detection and recognition, people analysis, object tracking and segmentation, human computer/robot interaction, behavior recognition, crowd analysis, fusion of vision with other sensing modalities, and so on.
Manuscripts should be formatted and submitted online according to the instructions for Pattern Recognition at http://www.elsevier.com/journals/pattern-recognition/0031-3203/guide-for-authors. The authors must select SI:VA Deep Learning when specifying the Article Type in the submission system. Submitted manuscripts must not have appeared or been under review elsewhere. All submitted manuscripts will be reviewed by at least three reviewers in accordance with the refereeing procedure of Pattern Recognition, and only those manuscripts that require minor revisions will be accepted for rapid publication in this special issue.

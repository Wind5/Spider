 I'm using jupyter notebook to write a deep neural network code. I've encountered this problem when trying to create a DNNClassifier.
 I am trying to use the C++ API of CNTK to achieve online learning. While reading the source code of the unit tests and the CNTKLibrary.h header, I only saw the Trainer.TrainMinibatch method to train a ...
 I am using CAFFE tool to work with semantic segmentation. However, I want to change to use Tensorflow. My question is that can we have a real-time running in inference for semantic segmentation using ...
 I'm training a segmentation model with the U-net architecture. The input image size is 250x250.
Currently, I've manually tweaked the paddings of some of the convolutional layers to ensure that the ...
 I have a time series data as shown above, with X axis is time (Seconds) and Y axis is weight. So as circled in image, if there exist a pattern where group of points downward and immediately the point ...
 Wanted to do something like this - http://scribbler.eye.gatech.edu/paper.pdf. could someone point me to working model for this? They have mentioned building on (https://github.com/TengdaHan/...
 I am doing a license plate detection program using YOLO. Since I don't have real data I have created 75K synthetic data. There is only one class: 'LicensePlate' .
 How can I train a TensorFlow (or Keras, or Caffe) model to detect an object and also its distance from the camera?
 I have a dataset with 1000s of labeled images, only one class (cars) and also their respective distances from the camera at the moment the pictures were taken.
 I have tagged dataset with a,b,c tags and have to tag incoming sequences with a,b,c,others categories. It should categorize and tag known sequences or say i haven't seen it before.
 GPU requirement for video summarizer using deep learning [on hold]
 I am working on video summarizer using SumMe dataset and access GPU with 5 GB memory. But when I run load the model for goes it goes out of memory. Even when one video at once with frames count of 200....
 Backpropagation from scratch  having trouble with some matrix multiplications
 I'm trying to implement a neural network from scratch and I'm having trouble correctly implementing the backpropagation. I feel like I'm either calling the wrong indexes of a weight/activation or I'm ...
 I am stuck on assignment from Andrew Ng DL-NN course. 
The code has a assertion when matrix gradient of the loss with respect to w ( dw ) must have the same shape of w ( .shape == ( 2, 1 ) ) but in ...
 How to prevent Nearest Neighbour Interpolation in scipy Image.resize module to not normalize the images in scene parsing annotations
 I am trying to reduce the dimensions of my image using PIL.Image.NEAREST interpolation in Image.resize(). The problem is that these images are annotations for a scene parsing task. So the pixel values ...
 I am trying to implement seq2seq model for text summarization using Tensorflow 1.3.0. 
I am trying to use MultiRNNCell and bidirectional_dynamic_rnn in encoding layer. I am missing something, but ...
 I am training a bi-directional multilayered Seq2Seq model. During training time, I see a lot of variation in my train loss witch each step of the training. 
 AttributeError: ‘LSTMStateTuple’ object has no attribute ‘get_shape’ while building a Seq2Seq Model using Tensorflow
 I am trying to work on Text Summarization using Amazon Reviews dataset. I am stuck at an error while building my model.
 I'm planning to use the TensorFlow Object detection API to detect objects like Arrows in my images. I am creating my training dataset and labelling my images.
 Calculate probability of test image resembling training image [on hold]
 I have my own dog images(unlabeled), and I want to check the probability of a test image being a dog image. How to go about it? Would a logistic regression work? What would be the labels then? Or any ...
 Is there a way how we can implement Mean Square False error (MSFE) and MFE (Mean False Error) Loss function in python .
 And also can anyone suggest what is the best loss function to be used for ...
 Why do we usually use color speech spectrogram rather than grayscale speech spectrogram in speech recognition?
 I want to know why we usually use color speech spectrogram rather than grayscale speech spectrogram in speech recognition and why the former has better recorecognition reslut than the later.
 What is the meaning of hand crafted features in computer vision problems?
 Are these the features which are manually labeled by humans? or Is there any technique for obtaining these features. Is this related to learned features?
 Input dimensionality using pre-trained CNNs in Keras for transfer learning
 I want to experiment with using some of the pre-trained CNN models available with the Keras library (e.g. Exception, ResNet50, etc) for feature extraction. I am trying to find out whether the input ...
 I'm currently trying to get into deep learning and I have a minor problem in understanding concerning CNNs. 
According to CS231n, the common formula for computing the output size of a conv. layer is ...
I have gained good understanding in the topic, but the data sets I have worked are pretty much ready to feed in the network(CIFAR) ,MNIST etc....
 I have trained a network with two convolution layers and two dense. 
then for some reason I need to add another convolution layer as first layer of network, So I add a layer and freeze other layers, ...
 How does the Tensorflow TrainingHelper know the vocab size used to decode?
 How does the decoder learn to map cell state to the vocab if we don't tell it the vocab size? In the tf dynamic decoding docs there's a code sample:
 I successfully compiled Caffe under Ubuntu and started to study how to define and train my own networks. However, I'm having trouble to understand how the convolutional layer produces its output. For ...
 I am training a Super-Resolution Network in Keras. I have a training set with images of dimensions (64,64) and I have images of dimensions (128,128) that I want to use as a validation set. Does it ...
 No squeezenet.ckpt download, Network Visualization, assignment3, cs231n Spring 2017 [on hold]
 After I run the get_assignment3_data.sh, I got three files named squeezenet.ckpt**. But there is no squeezenet.ckpt needed.
 New to Keras, trying to reimplement this following binary image classification example from: https://blog.keras.io/building-powerful-image-classification-models-using-very-little-data.html
 Mxnet is supposed to build and run, on CPU as well as on GPU, for multiple OSs including Windows.
I'm trying to build mxnet from source on Windows Server 2016 that has NVIDIA K80 GPU on it.
 I am a new user to caffe and I've basically made small modifications to the FCN model to train on my own data. I've noticed that after 680 iterations the loss has not changed. I thought maybe it was ...
 I am using an ImageDataGenerator to augment my images. I need to get the y labels from the generator.
Example : I have 10 training images, 7 are label 0 and 3 are label 1. I want to increase training ...
 I am trying to understand more about certain surprising results i see in implementing a tf graph .
The graph i am working with is just a forest (bunch of trees). This is just a plain forward inference ...
 CNN: Why stack same activation maps on top of each other
 I am wondering why we stack basically identical activation maps on top of each other? Since it's always the same filter applied on the same input, wouldn't it be always the same activation map? 
Previously I coded my own generator and Network, but here is the problem I preprocessed my data before passing it to the neural network. Now the task is to do ...
 What is Interpretability in Deep Learning Models? How it is different from writing models for machine learning and deep learning? [on hold]
 Basically I’m building Interpretability model in Deep Neural networks. But still at this point I don't have idea about implementing Interpretability models, Although I have implemented some models in ...
 I'm new in Deep Learning and I'm using Keras to get result. This time I'm trying to analyse sounds. I've converted sounds to text and sending it to NN. I'm using binary crossentropy as a loss and ...
 I tried the seq2seq pytorch implementation available here seq2seq . After profiling the evaluation(evaluate.py) code, the piece of code taking longer time was the decode_minibatch method
 word sequence prediction to form a semantically correct sentence using LSTM in python
 i was going through this article in which he took sentence as a time series https://softwaremill.com/deep-learning-for-nlp/
Using the ImageDataGenerator function, I apply some random transformations to the training images (e.g. rotation, shearing, zooming). 
I do know that dropout should be declared as a placeholder and keep_prob parameter during training and testing should be different. However still ...

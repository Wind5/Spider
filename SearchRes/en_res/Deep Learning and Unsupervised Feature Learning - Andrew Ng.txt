We consider the problem of building highlevel, class-specific feature detectors from only unlabeled data.
Authors: Quoc V. Le, Marc'Aurelio Ranzato, Rajat Monga, Matthieu Devin, Kai Chen, Greg S. Corrado, Jeffrey Dean and Andrew Y. Ng. (2012)
Machine learning is a very successful technology but applying it today often requires spending substantial effort hand-designing features. This is true for applications in vision, audio and text. To address this, Ng's group and others are working on "deep learning" algorithms, which can automatically learn feature representations (often from unlabeled data) thus avoiding a lot of time-consuming engineering. 
These algorithms are based on building massive artificial neural networks that were loosely inspired by cortical (brain) computations. As part of this work, Ng also founded and formerly led a project at Google to build massive deep learning algorithms. This work resulted in a highly distributed neural network with over 1 billion parameters trained on 16,000 CPU cores that learned by itself to discover high level concepts -- such as "cats" -- from watching unlabeled YouTube videos. 
For a high-level overview of the field, see the following video. 

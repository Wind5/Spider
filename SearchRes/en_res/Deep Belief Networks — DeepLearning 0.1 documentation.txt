This section assumes the reader has already read through Classifying MNIST digits using Logistic Regression
and Multilayer Perceptron and Restricted Boltzmann Machines (RBM). Additionally it uses the following Theano
ops, T.grad, Random numbers, floatX. If you intend to run the
[Hinton06] showed that RBMs can be stacked and trained in a greedy manner
to form so-called Deep Belief Networks (DBN). DBNs are graphical models which
learn to extract a deep hierarchical representation of the training data.
for the visible units conditioned on the hidden units of the RBM at level
distribution in the top-level RBM. This is illustrated in the figure below.
1. Train the first layer as an RBM that models the raw input as its visible layer.
2. Use that first layer to obtain a representation of the input that will
be used as data for the second layer. Two common solutions exist. This
3. Train the second layer as an RBM, taking the transformed data (samples or
mean activations) as training examples (for the visible layer of that RBM).
4. Iterate (2 and 3) for the desired number of layers, each time propagating
5. Fine-tune all the parameters of this deep architecture with respect to a
proxy for the DBN log- likelihood, or with respect to a supervised training
In this tutorial, we focus on fine-tuning via supervised gradient descent.
Specifically, we use a logistic regression classifier to classify the input
 based on the output of the last hidden layer of the
DBN. Fine-tuning is then performed via supervised gradient descent of the
non-null for the weights and hidden layer biases of each layer (i.e. null for
the visible biases of each RBM), this procedure is equivalent to initializing
the parameters of a deep MLP with the weights and hidden layer biases obtained
Why does such an algorithm work ? Taking as example a 2-layer DBN with hidden
(see also Bengio09]_ for a detailed derivation) that can be rewritten as,
the posterior of the first RBM if it were standalone, and the
probability for the same layer but defined by the entire DBN
It can be shown that if we initialize both hidden layers such that
divergence term is null. If we learn the first level RBM and then keep its
Also, notice that if we isolate the terms which depend only on , we
when is sampled from the training distribution for the first RBM.
To implement DBNs in Theano, we will use the class defined in the Restricted Boltzmann Machines (RBM)
tutorial. One can also observe that the code for the DBN is very similar with the one
The main difference is that we use the RBM class instead of the dA
We start off by defining the DBN class which will store the layers of the
MLP, along with their associated RBMs. Since we take the viewpoint of using
the RBMs to initialize an MLP, the code will reflect this by seperating as
much as possible the RBMs used to initialize the network and the MLP used for
 A deep belief network is obtained by stacking several RBMs on top of each
 other. The hidden layer of the RBM at layer `i` becomes the input of the
 RBM at layer `i+1`. The first layer RBM gets as input the input of the
 network, and the hidden layer of the last RBM represents the output. When
 used for classification, the DBN is treated as a MLP, by adding a logistic
 """This class is made to support a variable number of layers.
 :param numpy_rng: numpy random number generator used to draw initial
 :param theano_rng: Theano random generator; if None is given one is
 # the labels are presented as 1D vector of [int] labels
the MLP, while self.rbm_layers will store the RBMs used to pretrain each
that we replaced the non-linearity from tanh to the logistic function
is the depth of our model. We link the sigmoid layers such that they form an
MLP, and construct each RBM such that they share the weight matrix and the
 # the size of the input is either the number of hidden
 # units of the layer below or the input size if we are on
 # the input to this layer is either the activation of the
 # hidden layer below or the input of the DBN if you are on
 # going to only declare that the parameters of the
 # biases in the RBM are parameters of those RBMs, but not
 # Construct an RBM that shared weights with this layer
All that is left is to stack one last logistic regression layer in order to
form an MLP. We will use the LogisticRegression class introduced in
 # compute the cost for second phase of training, defined as the
 # negative log likelihood of the logistic regression (output) layer
 # compute the gradients with respect to the model parameters
 # symbolic variable that points to the number of errors made on the
The class also provides a method which generates training functions for each
of the RBMs. They are returned as a list, where element is a
function which implements one step of training for the RBM at layer
 Generates a list of functions, for performing one step of
 gradient descent at a given layer. The function will require
 as input the minibatch index, and to train an RBM you just
 :param k: number of Gibbs steps to do in CD-k / PCD-k
optionally lr  the learning rate. Note that the names of the parameters
are the names given to the Theano variables (e.g. lr) when they are
constructed and not the name of the python variables (e.g. learning_rate). Keep
this in mind when working with Theano. Optionally, if you provide k (the
number of Gibbs steps to perform in CD or PCD) this will also become an
In the same fashion, the DBN class includes a method for building the
 finetuning, a function `validate` that computes the error on a
 batch from the validation set, and a function `test` that
 computes the error on a batch from the testing set
 :param datasets: It is a list that contain all the datasets;
validation set and the entire test set to produce a list of the losses
The few lines of code below constructs the deep belief network:
For the pre-training stage, we loop over all the layers of the network. For
each layer, we use the compiled theano function which determines the
input to the i-th level RBM and performs one step of CD-k within this RBM.
This function is applied to the training set for a fixed number of epochs
 print(Pre-training layer %i, epoch %d, cost  % (i, epoch), end= )
The fine-tuning loop is very similar to the one in the Multilayer Perceptron tutorial,
the only difference being that we now use the functions given by
With the default parameters, the code runs for 100 pre-training epochs with
parameter updates. We use an unsupervised learning rate of 0.01, with a
supervised learning rate of 0.1. The DBN itself consists of three
hidden layers with 1000 units per layer. With early-stopping, this configuration
On an Intel(R) Xeon(R) CPU X5560 running at 2.80GHz, using a multi-threaded MKL
library (running on 4 cores), pretraining took 615 minutes with an average of
2.05 mins/(layer * epoch). Fine-tuning took only 101 minutes or approximately
Hyper-parameters were selected by optimizing on the validation error. We tested
learning rates in . We did not use any form of
regularization besides early-stopping, nor did we optimize over the number of
One way to improve the running time of your code (given that you have
sufficient memory available), is to compute the representation of the entire
dataset at layer i in a single pass, once the weights of the
-th layers have been fixed. Namely, start by training your first
layer RBM. Once it is trained, you can compute the hidden units values for
every example in the dataset and store this as a new dataset which is used to
train the 2nd layer RBM. Once you trained the RBM for layer 2, you compute, in
a similar fashion, the dataset for layer 3 and so on. This avoids calculating

 Literature Review of articles inDeep LearningNeural NetworksEvolutionary ComputingUnsupervised LearningSupervised LearningEvolutionary ComputationReinforcement LearningDeep Learning in Neural Networks: An OverviewArticle · Literature Review · April 2014 with 952 ReadsDOI: 10.1016/j.neunet.2014.09.003 · Source: arXivCite this publication1st Juergen SchmidhuberAbstractIn recent years, deep neural networks (including recurrent ones) have won
survey compactly summarises relevant work, much of it from the previous
millennium. Shallow and deep learners are distinguished by the depth of their
credit assignment paths, which are chains of possibly learnable, causal links
 CitationsCitations1029ReferencesReferences870Each layer of DNN performs a non-linear transformation of the input samples in the preceding layer to the following one. A good overview of DNNs can be found in[56]. Different from ANN, DNNs can be trained in a supervised or unsupervised manner[50,57]and they are also appropriate in the general area of Reinforcement Learning (RL)[58,59]. Intelligent condition monitoring method for bearing faults from highly compressed measurements using sparse over-complete features[Show abstract] [Hide abstract] ABSTRACT: Condition classification of rolling element bearings in rotating machines is important to prevent the breakdown of industrial machinery. A considerable amount of literature has been published on bearing faults classification. These studies aim to determine automatically the current status of a roller element bearing. Of these studies, methods based on compressed sensing (CS) have received some attention recently due to their ability to allow one to sample below the Nyquist sampling rate. This technology has many possible uses in machine condition monitoring and has been investigated as a possible approach for fault detection and classification in the compressed domain, i.e., without reconstructing the original signal. However, previous CS based methods have been found to be too weak for highly compressed data. The present paper explores computationally, for the first time, the effects of sparse autoencoder based over-complete sparse representations on the classification performance of highly compressed measurements of bearing vibration signals. For this study, the CS method was used to produce highly compressed measurements of the original bearing dataset. Then, an effective deep neural network (DNN) with unsupervised feature learning algorithm based on sparse autoencoder is used for learning over-complete sparse representations of these compressed datasets. Finally, the fault classification is achieved using two stages, namely, pre-training classification based on stacked autoencoder and softmax regression layer form the deep net stage (the first stage), and re-training classification based on backpropagation (BP) algorithm forms the fine-tuning stage (the second stage). The experimental results show that the proposed method is able to achieve high levels of accuracy even with extremely compressed measurements compared with the existing techniques. Full-text · Article · Jan 2018 Hosameldin Osman AhmedM.L.D. WongAsoke K NandiRead full-textThe past few years have seen a growing interest in AD from both academia and industry, fueled by a need for generic, user-friendly deep learning toolkits. The backpropagation learning algorithm used to train deep neural networks is a special case of reverse mode AD[31]. Consequently, several libraries available for deep learning also include high performance routines for constructing computational graphs and traversing them, from top to bottom, computing partial derivatives along the way to tune neurons in a multilayer neural network[1,3,35]. Distributed Automatic Differentiation for Ptychography[Show abstract] [Hide abstract] ABSTRACT: Synchrotron radiation light source facilities are leading the way to ultrahigh resolution X-ray imaging. High resolution imaging is essential to understanding the fundamental structure and interaction of materials at the smallest length scale possible. Diffraction based methods achieve nanoscale imaging by replacing traditional objective lenses by pixelated area detectors and computational image reconstruction. Among these methods, ptychography is quickly becoming the standard for sub-30 nanometer imaging of extended samples, but at the expense of increasingly high data rates and volumes. Full-text · Article · Dec 2017 Youssef S. G. NashedTom PeterkaJunjing DengChris JacobsenChris JacobsenRead full-textA representation learning approach to image segmentation in digital pathology reduces the time spent engineering features and ensures that the biological diversity and technical variance of the data set is captured. In general, deep neural networks work by arranging nodes or artificial " neurons " in successive, convolutional, max-pooling, and fully connected layers as described elsewere[16,17]. Parameters that specify neuron weighting are iteratively adjusted during training to approximate functions from data in a way that minimizes a loss function, which is typically correlated with the task at hand (e.g. Deep Learning Tissue Segmentation in Cardiac Histopathology Images[Show abstract] [Hide abstract] ABSTRACT: Cardiac biopsies are obtained for the diagnosis of acute heart failure as well as post-heart-transplant rejection. On histology, both are characterized by an expansion of the cellular and acellular stromal tissue as well as morphologic changes within myocytes, among other features. There is growing evidence, from a number of diseases, that computer-extracted features of tissue and nuclear architecture are not only useful for diagnostics, but can also predict disease recurrence, progression, and patient outcome. Automated tools to segment myocytes and stroma with high fidelity are a critical first step toward developing predictive models to improve diagnosis, prognosis, and reproducibility in cardiac pathology. Whole-slide imaging in digital pathology is producing large, rich data sets for machine learning algorithms that learn features representations directly from data, such as deep neural networks or “deep learning”. Deep learning has achieved state of the art performance in computer vision and is becoming ubiquitous within the realm of digital pathology. Here, we present a deep learning framework for myocyte and stroma segmentation in H&E stained cardiac biopsies using a data set of 103 patients with clinical heart failure or non-heart failure controls. We provide a tutorial for how to use the AlexNet architecture, implemented in Caffe, to train a pixel-level classifier for segmentation. We compare the performance of our deep learning approach to a random forest classifier with 333 intensity and texture features and test on 20 held-out patient images with expert ground-truth annotation of tissue boundaries. We find our deep learning segmentation outperforms random forests in terms of mean (a) AUC (0.95 vs 0.80), (b) F-score (0.96 vs 0.91), (c) TPR (0.96 vs 0.92), (d) TNR (0.94 vs 0.67), and (e) modified Hausdorff distance on the segmentation perimeter pixels (51 vs 122).Chapter · Dec 2017 · Journal of the Brazilian Computer SocietyJeffrey John NirschlAndrew JanowczykEliot G. Peyster+1 more author...Renee FrankReadMost of the studies concentrate on proposing more elaborated features to represent documents in the vector space model, including the use of topic model techniques, such as LSI and LDA, to obtain latent semantic features. Deep learning[149]is currently applied to represent independent terms through their associated concepts, in an attempt to narrow the relationships between the terms[150,151]. The use of distributed word representations (word embeddings) can be seen in several works of this area in tasks such as classification[88,152,153], summarization[154], and information retrieval[155]. Text mining and semantics: a systematic mapping study[Show abstract] [Hide abstract] ABSTRACT: As text semantics has an important role in text meaning, the term semantics has been seen in a vast sort of text mining studies. However, there is a lack of studies that integrate the different research branches and summarize the developed works. This paper reports a systematic mapping about semantics-concerned text mining studies. This systematic mapping study followed a well-defined protocol. Its results were based on 1693 studies, selected among 3984 studies identified in five digital libraries. The produced mapping gives a general summary of the subject, points some areas that lacks the development of primary or secondary studies, and can be a guide for researchers working with semantics-concerned text mining. It demonstrates that, although several studies have been developed, the processing of semantic aspects in text mining remains an open research problem. Full-text · Article · Dec 2017 Roberta Akemi SinoaraJoão AntunesSolange Oliveira RezendeRead full-textELM trains extremely fast and has good generalization. ELM has been successfully applied for pattern recognition, image classification, fault diagnosis, big data analytics, and machine learning[6][7][8][9]. ELM has been effectively used for distributed applications parallel computation-based problems[10][11][12][13]. But choosing input weights and bias randomly is an issue to be dealt with. Impact of Air Pollution on Respiratory Diseases: Correlation and Classification by Multivariate Data Analysis[Show abstract] [Hide abstract] ABSTRACT: Respiratory diseases are emerging as the major health problem across India and Delhi tops in lung disease-related issues. The main reason for such rise in respiratory problems in Delhi is air pollution. Among air pollutants, particulate matter (PM2.5) is very hazardous and it is instrumental in causing lung-related diseases. In this paper, an extreme learning machine (ELM) based on statistically controlled activation weight initialization is used to learn and measure the correlation between PM2.5 and lung-related problems in Delhi. ELM was trained and tested with PM and lung functionality-related medical data. PM2.5 level data of different areas of Delhi are collected during January 2016 to December 2016. Lung function-related medical data are collected from reputed hospitals in Delhi and analyzed. Results of sputum sample test and spirometry tests conducted on both adults and school children was collected. The test results for both adults and school children are analyzed, and correlation coefficients are evaluated using linear analysis and Spearman’s analysis. The correlation results were positive and thus proving that the increase in lung-related diseases in Delhi is directly related to rising PM2.5 level in the city.Article · Dec 2017 M. DeepaM. RajalakshmiR. NedunchezhianRead? the development of deep learning, including the solutions for the vanishing gradient problem by Restricted Boltzmann Machines [14, 5, 25]; Overview of the CPS for Smart Factories Project: Deep Learning, Knowledge Acquisition, Anomaly Detection and Intelligent User Interfaces[Show abstract] [Hide abstract] ABSTRACT: Industry 4.0 factories become more and more complex with increased maintenance costs. Reducing costs by cyber-physical (CP) controllers should ensure the commercialization of the CPS for smart factory project results. We implement multi-adaptive CP controllers in the following domains: industrial robot arms, car manufacturing, steel industry, and assembly lines in general. The main objective is to implement such controllers for these application domains and let the industry partners provide feedback about the cost reduction potential. In this paper, we describe the technical infrastructure including deep learning and knowledge acquisition submodules, followed by anomaly detection modules and intelligent user interfaces in the IoT (Internet of Things) paradigm. In addition, we report on three concrete use case implementations of industrial robots and anomaly modeling, knowledge management and anomaly treatment in the steel domain, and anomaly detection in the energy domain. Full-text · Chapter · Oct 2017 · Journal of the Brazilian Computer SocietyDaniel SonntagSonja ZillnerPatrick van der SmagtAndrás LörinczAndrás LörinczRead full-textShow moreRecommendationsDiscover more publications, questions and projects in Deep LearningProjectMulti-script handwritten character recognition using feature descriptors and machine learningLambert SchomakerMarco A. WieringOlarik SurintaThe recognition of handwriting, in multiple scripts (Thai, Bangla, Odia) and from various historical periods is still a challenging problem at all levels of processing from
intensity normalization …" [more]View projectProjectDiscretely Weighted Recurrent Neural NetworksJohn CorrellPossible logic gate creation and learning. View projectProjectQuantum Intelligent CosmologyAngus McCossIdentify candidate intelligent metaheuristics for the evolution of everything, from mathematics, through physics, to life; and from quantum foundations to cosmological scales. View projectProjectCellular Network Resource AllocationPhilip OmolayeJoseph M MomGabriel A. IgwueThe goal is to model and develop an module that is capable of predicting and monitor resource allocation on the network and automatically allocate resources appropriately when needed. This is with …" [more]View projectArticleOn Learning to Think: Algorithmic Information Theory for Novel Combinations of Reinforcement Learnin...November 2015This paper addresses the general problem of reinforcement learning (RL) in
high-dimensional video input. However, real brains are more powerful in many
ways. In particular, they learn a predictive model of their initially unknown
environment, and somehow... [Show full abstract]Read moreArticleDeep LearningJanuary 2016Deep learning artificial neural networks have won numerous contests in pattern recognition and machine learning. They are now widely used by the worlds most valuable public companies. I review the most popular algorithms for feedforward and recurrent networks and their history. Read moreChapterDeep LearningJanuary 2017Deep learning artificial neural networks have won numerous contests in pattern recognition and machine learning. They are now widely used by the worlds most valuable public companies. I review the most popular algorithms for feedforward and recurrent networks and their history. Read moreArticleMy First Deep Learning System of 1991 + Deep Learning Timeline 1962-2013December 2013Deep Learning has attracted significant attention in recent years. Here I
present a brief overview of my first Deep Learner of 1991, and its historic
context, with a timeline of Deep Learning highlights. Read moreDiscover moreData provided are for informational purposes only. Although carefully collected, accuracy cannot be guaranteed. Publisher conditions are provided by RoMEO. Differing provisions from the publishers actual policy or licence agreement may be applicable.This publication is from a journal that may support self archiving.Learn moreLast Updated: 02 Jul 17 

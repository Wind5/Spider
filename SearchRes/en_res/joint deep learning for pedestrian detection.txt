Feature extraction, deformation handling, occlusion handling, and classification are four important components in pedestrian detection. 
Existing methods learn or design these components either individually or sequentially. 
The interaction among these components is not yet well explored. 
This paper proposes that they should be jointly learned in order to maximize their strengths through cooperation. 
We formulate these four components into a joint deep learning framework and propose a new deep network architecture
 A unified deep model for jointly learning feature extraction, a part deformation model, an occlusion model and classification. With the deep model, these components interact with each other in the learning process, which allows each component to maximize its strength when cooperating with others .
 We enrich the operation in deep models by incorporating the deformation layer into the convolutional neural networks (CNN). With this layer, various deformation handling approaches can be applied to our deep model.
 The features are learned from pixels through interaction with deformation and occlusion handling models . Such interaction helps to learn more discriminative features.
1. Put all of the documents into the same folder and decompress them using the command "extract to here". Suppose the root folder is "root", then you should have three folders "root/CNN", "root/data", "root/model", "root/NN", "root/tmptoolbox", "root/util", and "root/dbEval". For "root/data", there should be 4 folders: "root/data/CaltechTest", "root/data/CaltechTrain", "root/data/ETH", and "root/data/INRIATrain". 
2. Run the "cnnexamples.m" or "testing.m." in the folder "root/CNN" to obtain the results.
This site was built using Bootstrap, a front-end framework for web development. Thanks to the following site developers and all lab members that contribute their suggestions and information

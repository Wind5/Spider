IEEE Conference on Computer Vision and Pattern Recognition (CVPR), 2012, Providence, Rhode Island
Proceedings of the 15th International Conference on Artificial Intelligence and Statistics (AISTATS), 2012, La Palma, Canary Islands 
RBM learning using approximate ML methods is known to be hard when the input data is not sparse. We
present an extremely simple data normalization technique to improve learning. The method consists of
only 3 additional lines of code and is akin to training on zero-meaned data.
Object recognition in the real world must deal with occlusions and clutter. We investigate a modified version of Deep Boltzmann Machine (DBM) called Denoising Gated Boltzmann Machine (DGBM) which uses feedback dynamics to achieve lower recognition error rates.
In NIPS Workshop on Transfer Learning by Learning Rich Generative Models, Whistler, Canada, 2010.
We show that by performing denoising using a Deep Belief Net prior to classification leads to improved accuracy on noisy and occluded test data.
I completed my Masters of Mathematics degree in 2010 at the University of Waterloo in Computer Science. My supervisor was Chris Eliasmith.
 Prior to my Masters degree, I was part of the class of 2008 in Mechatronics Engineering at the University of Waterloo. I went to the excellent Thomas Worthington HS and Forest Hill Collegiate Institute.
I'm also a Canadian master at the game of chess and two time ('01 & '02) high school chess champion in the state of Ohio.

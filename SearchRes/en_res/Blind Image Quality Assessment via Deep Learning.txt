 Blind Image Quality Assessment via Deep LearningArticle · August 2014 with 356 ReadsDOI: 10.1109/TNNLS.2014.2336852 · Source: PubMedCite this publication1st Weilong Hou2nd Xinbo Gao43.3 · Xidian University3rd Dacheng Tao4th Wei Liu35.7 · Northeastern University (Shenyang, China)AbstractThis paper investigates how to blindly evaluate the visual quality of an image by learning rules from linguistic descriptions. Extensive psychological evidence shows that humans prefer to conduct evaluations qualitatively rather than numerically. The qualitative evaluations are then converted into the numerical scores to fairly benchmark objective image quality assessment (IQA) metrics. Recently, lots of learning-based IQA models are proposed by analyzing the mapping from the images to numerical ratings. However, the learnt mapping can hardly be accurate enough because some information has been lost in such an irreversible conversion from the linguistic descriptions to numerical scores. In this paper, we propose a blind IQA model, which learns qualitative evaluations directly and outputs numerical scores for general utilization and fair comparison. Images are represented by natural scene statistics features. A discriminative deep model is trained to classify the features into five grades, corresponding to five explicit mental concepts, i.e., excellent, good, fair, poor, and bad. A newly designed quality pooling is then applied to convert the qualitative labels into scores. The classification framework is not only much more natural than the regression-based models, but also robust to the small sample size problem. Thorough experiments are conducted on popular databases to verify the models effectiveness, efficiency, and robustness.
 CitationsCitations50ReferencesReferences43We also compared the proposed PQR-based model against existing BIQA methods on the four databases. Since the split of training and testing sets will affect prediction accuracy, for a fair comparison, we re-ran the source codes of the DIIVINE[8], CORNIA[9], BRISQUE[10], NIQE[46], IL-NIQE[47], HOSA[19]and FRIQUEE-ALL[14]models using the same training and testing splits as we used for the PQR model. 4 Since both NIQE and IL-NIQE do not require any training, we directly evaluated them on the testing sets. A Probabilistic Quality Representation Approach to Deep Blind Image Quality Prediction[Show abstract] [Hide abstract] ABSTRACT: Blind image quality assessment (BIQA) remains a very challenging problem due to the unavailability of a reference image. Deep learning based BIQA methods have been attracting increasing attention in recent years, yet it remains a difficult task to train a robust deep BIQA model because of the very limited number of training samples with human subjective scores. Most existing methods learn a regression network to minimize the prediction error of a scalar image quality score. However, such a scheme ignores the fact that an image will receive divergent subjective scores from different subjects, which cannot be adequately represented by a single scalar number. This is particularly true on complex, real-world distorted images. Moreover, images may broadly differ in their distributions of assigned subjective scores. Recognizing this, we propose a new representation of perceptual image quality, called probabilistic quality representation (PQR), to describe the image subjective score distribution, whereby a more robust loss function can be employed to train a deep BIQA model. The proposed PQR method is shown to not only speed up the convergence of deep model training, but to also greatly improve the achievable level of quality prediction accuracy relative to scalar quality score regression methods.Article · Aug 2017 · Remote SensingHui ZengLei ZhangAlan C. BovikReadThe image evaluation methods which are based on deep learning are worthy of being studied[171][172][173][174], because the mathematical based objective evaluation index system has various shortcomings at present. Since the special nature of IR and VI images[175][176], the conventional image fusion quality evaluation is not fully adapted to this field. A Survey of Infrared and Visual Image Fusion Methods[Show abstract] [Hide abstract] ABSTRACT: Infrared (IR) and visual (VI) image fusion is designed to fuse multiple source images into a comprehensive image to boost imaging quality and reduce redundancy information, which are widely used in various imaging equipment to improve the visual ability of human and robot. The accurate, reliable and complementary descriptions of the scene in fused images make these techniques be widely used in various fields. In recent years, a large number of fusion methods for IR and VI images have been proposed due to the ever-growing demands and the progress of image representation methods; however, there has not been published an integrated survey paper about the this field in last several years. Therefore, we make a survey to report the algorithmic developments of IR and VI image fusion. In this paper, we first characterize the IR and VI image fusion technique based applications to represent an overview of the research status. Then we present a synthesize survey of the state of the art. Thirdly, frequently-used image fusion quality measures are introduced. Fourthly, we perform some experiments of typical methods. At last, we summarize the corresponding tendencies and challenges in IR and VI image fusion. This survey concludes that although various IR and VI image fusion methods have been proposed, there still exist further improvements or potential research directions in different applications of IR and VI image fusion. Full-text · Article · Jul 2017 Jin XinQian JiangShaowen Yao+1 more author...Dongming ZhouRead full-textHou et al.[53]designed a deep learning model trained by deep belief net and then fine-tuned it for image quality estimation. Yet it is found that some deep learning based methods need to handcraft features[49][50][51][52]or redundant operations[50,52,53]. This paper presents a shallow CNN to address BISA. A shallow convolutional neural network for blind image sharpness assessment[Show abstract] [Hide abstract] ABSTRACT: Blind image quality assessment can be modeled as feature extraction followed by score prediction. It necessitates considerable expertise and efforts to handcraft features for optimal representation of perceptual image quality. This paper addresses blind image sharpness assessment by using a shallow convolutional neural network (CNN). The network takes single feature layer to unearth intrinsic features for image sharpness representation and utilizes multilayer perceptron (MLP) to rate image quality. Different from traditional methods, CNN integrates feature extraction and score prediction into an optimization procedure and retrieves features automatically from raw images. Moreover, its prediction performance can be enhanced by replacing MLP with general regression neural network (GRNN) and support vector regression (SVR). Experiments on Gaussian blur images from LIVE-II, CSIQ, TID2008 and TID2013 demonstrate that CNN features with SVR achieves the best overall performance, indicating high correlation with human subjective judgment. © 2017 Yu et al. This is an open access article distributed under the terms of the Creative Commons Attribution License, which permits unrestricted use, distribution, and reproduction in any medium, provided the original author and source are credited. Full-text · Article · May 2017 Nicolas Yushibin WuLei Wang+1 more author...Fan JiangRead full-textIn many real-world classification tasks, it is difficult to satisfy the assumption that the training data and the data to be classified share the same distribution and the same feature space. For example, suppose that we have trained an AlexNet[12]for an object classification task, but we now wish to evaluate the quality of images[13],[14], or we simply want to know how to take better selfies[15]. In the above cases, transfer learning has the potential to improve performance and reduce the effort required for data labelling. Liver Fibrosis Classification Based on Transfer Learning and FCNet for Ultrasound Images[Show abstract] [Hide abstract] ABSTRACT: Diagnostic ultrasound offer great improvements in diagnostic accuracy and robustness. However, it is difficult to make subjective and uniform diagnoses because the quality of ultrasound images can be easily influenced by machine settings, the characteristics of ultrasonic waves, the interactions between ultrasound and body tissues, and other uncontrollable factors. In this paper, we propose a novel liver fibrosis classification method based on transfer learning (TL) using VGGNet and a deep classifier called fully connected network (FCNet). In case of insufficient samples, deep features extracted using TL strategy can provide sufficient classification information. These deep features are then sent to FCNet for the classification of different liver fibrosis statuses. With this framework, tests show that our deep features combined with the FCNet can provide suitable information to enable the construction of the most accurate prediction model when compared with other methods. Full-text · Article · Mar 2017 Dan MengLibo ZhangGuitao Cao+1 more author...Wenming CaoRead full-textThis method is not applicable to cases where the panchromatic image is not available. There are some other no-reference image assessment methods designed for color images[15][16][17], but they cannot be applied to hyperspectral image directly. These methods can only assess spatial quality and give quality scores which reflect humans subjective visual sense. No-Reference Hyperspectral Image Quality Assessment via Quality-Sensitive Features Learning[Show abstract] [Hide abstract] ABSTRACT: Assessing the quality of a reconstructed hyperspectral image (HSI) is of significance for restoration and super-resolution. Current image quality assessment methods such as peak signal-noise-ratio require the availability of pristine reference image, which is often not available in reality. In this paper, we propose a no-reference hyperspectral image quality assessment method based on quality-sensitive features extraction. Difference of statistical properties between pristine and distorted HSIs is analyzed in both spectral and spatial domains, then multiple statistics features that are sensitive to image quality are extracted. By combining all these statistics features, we learn a multivariate Gaussian (MVG) model as benchmark from the pristine hyperspectral datasets. In order to assess the quality of a reconstructed HSI, we partition it into different local blocks and fit a MVG model on each block. A modified Bhattacharyya distance between the MVG model of each reconstructed HSI block and the benchmark MVG model is computed to measure the quality. The final quality score is obtained by average pooling over all the blocks. We assess five state-of-the-art super-resolution methods on Airborne Visible Infrared Imaging Spectrometer (AVIRIS) and Hyperspec-VNIR-C (HyperspecVC) data using our proposed method. It is verified that the proposed quality score is consistent with current reference-based assessment indices, which demonstrates the effectiveness and potential of the proposed no-reference image quality assessment method. Full-text · Article · Mar 2017 Jingxiang YangYongqiang ZhaoChen YiJonathan Cheung-Wai ChanJonathan Cheung-Wai ChanRead full-textPerforming semi-supervised learning, Tang et al. [16] extract LBIQ features [15] , wisely pre-train a Restricted Boilzman Machine with auxiliary data and fine-tune the network achieving the state-of-the-art performance. Hou et al. [5] propose a reasonable classification-based model with quality pooling treating IQA problem in a different view. Objectness and Saliency in IQA: To the best of our knowledge, attentional models have not been applied to general-purpose NR-IQA, but semantic objectness or saliency is widely accepted. Recurrent Attentional Model for No-Reference Image Quality Assessment[Show abstract] [Hide abstract] ABSTRACT: This paper presents a recurrent attentional model (RAM) for general no-reference image quality assessment (NR-IQA), that is to predict the perceptual quality score for an input image without using any reference image and/or prior knowledge regarding underlying distortions. The proposed RAM is inspired by the well known visual attention mechanism, both covert and overt, which affects many aspects of visual perception including image quality assessment. The attentional mechanism is, however, largely ignored in the NR-IQA literature. The proposed RAM hypothesizes that the attentional scanning path in an image should contain intrinsic information for IQA. The RAM thus consists of three components: a glimpse sub-network analyzing the quality at a fixation using multi-scale information, a location sub-network selecting where to look next by sampling a stochastic node, and a recurrent network aggregating information along the scanning path to compute the final prediction. The RAM is formulated under multi-task learning for the joint prediction of distortion type and image quality score and for the REINFORCE rule~\cite{williams1992simple} used to handle the stochastic node. The RAM is trained through back-propagation. In experiments, the RAM is tested on the TID2008 dataset with promising performance obtained, which shows the effectiveness of the proposed RAM. Furthermore, the RAM is very efficient in the sense that a small number of glimpses are used usually in testing. Full-text · Article · Dec 2016 · Remote SensingDiqi ChenYizhou WangTianfu WuWen GaoWen GaoRead full-textShow moreRecommendationsDiscover more publications, questions and projects in Deep LearningProjectImage Quality AssessmentXinbo GaoWen LuLihuo He[...]Xiumei Wang1. Full-reference Image or Video Quality Assessment
 4. Image Quality Assessment Based on fi…" [more]View projectProjectHeterogeneous Image SynthesisXinbo Gao1. Image Super-resolution Reconstruction from Multi-frame Images or Video Sequence
3. High-resolution Face Reconstructio…" [more]View projectProjectHeterogeneous Face Image Synthesis and RecognitionNannan WangXinbo GaoJie Li[...]Mingrui ZhuFace Sketch-Photo Synthesis
Face Analysis View projectArticleNonlinear Dimensionality Reduction with Local Spline Embedding.January 2009This paper presents a new algorithm for Non-Linear Dimensionality Reduction (NLDR). Our algorithm is developed under the conceptual framework of compatible mapping. Each such mapping is a compound of a tangent space projection and a group of splines. Tangent space projection is estimated at each data point on the manifold, through which the data point itself and its neighbors are represented... [Show full abstract]Read moreArticleA Novel Compressed Images Quality Metric.April 2011 · International Journal of Image and GraphicsAs the performance indicator of the image processing algorithms or systems, image quality assessment (IQA) has attracted the attention of many researchers. Aiming to the widely used compression standards, JPEG and JPEG2000, we propose a new no reference (NR) metric for compressed images to do IQA. This metric exploits the causes of distortion by JPEG and JPEG2000, employs the directional... [Show full abstract]Read moreArticleImage Watermarking Based on Invariant Representation of Polar Sine TransformOctober 2011 · IEICE Transactions on Fundamentals of Electronics Communications and Computer Sciences · Impact Factor: 0.23This letter presents a new image watermarking scheme using Polar Sine Transform (PST), a new kind of orthogonal moment defined on a circular domain. The PSTs are easy to compute and have no numerical stability problem, thus are more suitable for watermarking. In the proposed method, the PSTs are modified according to the binary watermark bits, producing a compensation image. The watermarked... [Show full abstract]Read moreArticleVideo Watermarking by Space-Time Interest PointsAugust 2008 · IEICE Transactions on Fundamentals of Electronics Communications and Computer Sciences · Impact Factor: 0.23This letter presents a novel robust video watermarking scheme based on space-time interest points. These points correspond to inherent structures of the video so that they can be used as synchronization signals for watermark embedding and extraction. In the proposed scheme, local regions are generated using the space-time interest points, and the watermark is embedded into all the regions by... [Show full abstract]Read moreDiscover moreData provided are for informational purposes only. Although carefully collected, accuracy cannot be guaranteed. Publisher conditions are provided by RoMEO. Differing provisions from the publishers actual policy or licence agreement may be applicable.This publication is from a journal that may support self archiving.Learn moreLast Updated: 29 Jul 17 

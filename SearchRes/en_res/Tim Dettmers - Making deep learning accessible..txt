2017-08-31 by Tim Dettmers 9 Comments This blog post looks at the growth of computation, data, deep learning researcher demographics to show that the field of deep learning could stagnate over slowing growth. We will look at recent deep learning research papers which strike up similar problems but also demonstrate how one could to solve these problems. After discussion of these papers, I conclude with promising research directions which face these challenges head on.
Filed Under: Deep Learning Tagged With: AI, Computational growth, Deep Learning, Future, Research DirectionsWhich GPU(s) to Get for Deep Learning: My Experience and Advice for Using GPUs in Deep Learning 
2017-04-09 by Tim Dettmers 547 Comments Deep learning is a field with intense computational requirements and the choice of your GPU will fundamentally determine your deep learning experience. With no GPU this might look like months of waiting for an experiment to finish, or running an experiment for a day or more only to see that the chosen parameters were off. With a good, solid GPU, one can quickly iterate over deep learning networks, and run experiments in days instead of months, hours instead of days, minutes instead of hours. So making the right choice when it comes to buying a GPU is critical. So how do you select the GPU which is right for you? This blog post will delve into that question and will lend you advice which will help you to make choice that is right for you.
 [Read more] about Which GPU(s) to Get for Deep Learning: My Experience and Advice for Using GPUs in Deep Learning
Filed Under: Deep Learning, Hardware Tagged With: CUDA, Deep Learning, GPU, Neural NetworksThe Brain vs Deep Learning Part I: Computational Complexity — Or Why the Singularity Is Nowhere Near 
2015-07-27 by Tim Dettmers 158 Comments In this blog post I will delve into the brain and explain its basic information processing machinery and compare it to deep learning. I do this by moving step-by-step along with the brains electrochemical and biological information processing pipeline and relating it directly to the architecture of convolutional nets. Thereby we will see that a neuron and a convolutional net are very similar information processing machines. While performing this comparison, I will also discuss the computational complexity of these processes and thus derive an estimate for the brains overall computational power. I will use these estimates, along with knowledge from high performance computing, to show that it is unlikely that there will be a technological singularity in this century.
 [Read more] about The Brain vs Deep Learning Part I: Computational Complexity — Or Why the Singularity Is Nowhere Near
Filed Under: Neuroscience Tagged With: Deep Learning, dendritic spikes, high performance computing, neuroscience, singularityUnderstanding Convolution in Deep Learning 
2015-03-26 by Tim Dettmers 99 Comments Convolution is probably the most important concept in deep learning right now. It was convolution and convolutional nets that catapulted deep learning to the forefront of almost any machine learning task there is. But what makes convolution so powerful? How does it work? In this blog post I will explain convolution and relate it to other concepts that will help you to understand convolution thoroughly.
Filed Under: Deep Learning Tagged With: Convolution, convolution kernel, Convolutional Nets, Deep LearningA Full Hardware Guide to Deep Learning 
2015-03-09 by Tim Dettmers 568 Comments Deep Learning is very computationally intensive, so you will need a fast CPU with many cores, right? Or is it maybe wasteful to buy a fast CPU? One of the worst things you can do when building a deep learning system is to waste money on hardware that is unnecessary. Here I will guide you step by step through the hardware you will need for a cheap high performance system.
 [Read more] about A Full Hardware Guide to Deep Learning
Filed Under: Hardware Tagged With: CPU, Deep Learning, hardware, machine learning, PCI, RAM, SSDHow to Parallelize Deep Learning on GPUs Part 2/2: Model Parallelism 
2014-11-09 by Tim Dettmers 19 Comments In my last blog post I explained what model and data parallelism is and analysed how to use data parallelism effectively in deep learning. In this blog post I will focus on model parallelism.
 [Read more] about How to Parallelize Deep Learning on GPUs Part 2/2: Model Parallelism
Filed Under: Hardware Tagged With: CUDA, Deep Learning, GPU, HPC, Neural Networks, Parallel ComputingHow to Parallelize Deep Learning on GPUs Part 1/2: Data Parallelism 
2014-10-09 by Tim Dettmers 17 Comments In my last blog post I showed what to look out for when you build a GPU cluster. Most importantly, you want a fast network connection between your servers and using MPI in your programming will make things much easier than to use the options available in CUDA itself.
In this blog post I explain how to utilize such a cluster to parallelize neural networks in different ways and what the advantages and downfalls are for such algorithms. The two different algorithms are data and model parallelism. In this blog entry I will focus on data parallelism.
 [Read more] about How to Parallelize Deep Learning on GPUs Part 1/2: Data Parallelism
Filed Under: Hardware Tagged With: CUDA, Deep Learning, GPU, HPC, MPI, Neural NetworksHow To Build and Use a Multi GPU System for Deep Learning 
2014-09-21 by Tim Dettmers 117 Comments When I started using GPUs for deep learning my deep learning skills improved quickly. When you can run experiments of algorithms and algorithms with different parameters and gain rapid feedback you can just learn much more quickly. At the beginning, deep learning is a lot of trial and error: You have to get a feel what parameters need to be adjusted, or what puzzle piece is missing in order to get a good result. A GPU helps you to fail quickly and learn important lessons so that you can keep improving. Soon my deep learning skills were sufficient to take the 2nd place in the Crowdflower competition where the task was to predict weather labels from given tweets (sunny, raining etc.).
After this success I was tempted to use multiple GPUs in order to train deep learning algorithms even faster. I also took interest in learning very large models which do not fit into a single GPU. I thus wanted to build a little GPU cluster and explore the possibilities to speed up deep learning with multiple nodes with multiple GPUs. At the same time I was offered to do contract work as a data base developer through my old employer. This gave me opportunity to get the money to build the GPU cluster I thought of.
 [Read more] about How To Build and Use a Multi GPU System for Deep Learning
Filed Under: Hardware Tagged With: Deep Learning, GPU, HPC, MPI, Neural NetworksPrimary SidebarSubscribe to Blog via Email
Enter your email address to subscribe to this blog and receive notifications of new posts by email.

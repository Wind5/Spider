Time Series prediction is a difficult problem both to frame and to address with machine learning.
In this post, you will discover how to develop neural network models for time series prediction in Python using the Keras deep learning library.
How to phrase time series prediction as a regression problem and develop a neural network model for it.
How to frame time series prediction with a time lag and develop a neural network model for it.
Update Oct/2016: Replaced graphs with more accurate versions, commented on the limited performance of the first method.
Update Mar/2017: Updated example for Keras 2.0.2, TensorFlow 1.0.1 and Theano 0.9.0.
The problem we are going to look at in this post is the international airline passengers prediction problem.
This is a problem where given a year and a month, the task is to predict the number of international airline passengers in units of 1,000. The data ranges from January 1949 to December 1960 or 12 years, with 144 observations.
The dataset is available for free from the DataMarket webpage as a CSV download with the filename international-airline-passengers.csv.
Below is a sample of the first few lines of the file.
We can load this dataset easily using the Pandas library. We are not interested in the date, given that each observation is separated by the same interval of one month. Therefore when we load the dataset we can exclude the first column.
The downloaded dataset also has footer information that we can exclude with the skipfooter argument to pandas.read_csv() set to 3 for the 3 footer lines. Once loaded we can easily plot the whole dataset. The code to load and plot the dataset is listed below.
You can also see some periodicity to the dataset that probably corresponds to the northern hemisphere summer holiday period.
We are going to keep things simple and work with the data as-is.
Normally, it is a good idea to investigate various data preparation techniques to rescale the data and to make it stationary.
Take my free 2-week email course and discover MLPs, CNNs and LSTMs (with sample code).
Click to sign-up now and also get a free PDF Ebook version of the course.
We want to phrase the time series prediction problem as a regression problem.
That is, given the number of passengers (in units of thousands) this month, what is the number of passengers next month.
We can write a simple function to convert our single column of data into a two-column dataset. The first column containing this months (t) passenger count and the second column containing next months (t+1) passenger count, to be predicted.
Before we get started, lets first import all of the functions and classes we intend to use. This assumes a working SciPy environment with the Keras deep learning library installed.
We can also use the code from the previous section to load the dataset as a Pandas dataframe. We can then extract the NumPy array from the dataframe and convert the integer values to floating point values which are more suitable for modeling with a neural network.
# load the datasetdataframe = pandas.read_csv('international-airline-passengers.csv', usecols=[1], engine='python', skipfooter=3)dataset = dataframe.valuesdataset = dataset.astype('float32')
After we model our data and estimate the skill of our model on the training dataset, we need to get an idea of the skill of the model on new unseen data. For a normal classification or regression problem we would do this using cross validation.
With time series data, the sequence of values is important. A simple method that we can use is to split the ordered dataset into train and test datasets. The code below calculates the index of the split point and separates the data into the training datasets with 67% of the observations that we can use to train our model, leaving the remaining 33% for testing the model.
# split into train and test setstrain_size = int(len(dataset) * 0.67)test_size = len(dataset) - train_sizetrain, test = dataset[0:train_size,:], dataset[train_size:len(dataset),:]print(len(train), len(test))
Now we can define a function to create a new dataset as described above. The function takes two arguments, the dataset which is a NumPy array that we want to convert into a dataset and the look_back which is the number of previous time steps to use as input variables to predict the next time period, in this case, defaulted to 1. 
This default will create a dataset where X is the number of passengers at a given time (t) and Y is the number of passengers at the next time (t + 1).
It can be configured and we will look at constructing a differently shaped dataset in the next section.
# convert an array of values into a dataset matrixdef create_dataset(dataset, look_back=1):dataX, dataY = [], []for i in range(len(dataset)-look_back-1):a = dataset[i:(i+look_back), 0]dataX.append(a)dataY.append(dataset[i + look_back, 0])return numpy.array(dataX), numpy.array(dataY)
If you compare these first 5 rows to the original dataset sample listed in the previous section, you can see the X=t and Y=t+1 pattern in the numbers.
Lets use this function to prepare the train and test datasets ready for modeling.
We can now fit a Multilayer Perceptron model to the training data.
We use a simple network with 1 input, 1 hidden layer with 8 neurons and an output layer. The model is fit using mean squared error, which if we take the square root gives us an error score in the units of the dataset.
I tried a few rough parameters and settled on the configuration below, but by no means is the network listed  optimized.
# create and fit Multilayer Perceptron modelmodel = Sequential()model.add(Dense(8, input_dim=look_back, activation='relu'))model.add(Dense(1))model.compile(loss='mean_squared_error', optimizer='adam')model.fit(trainX, trainY, epochs=200, batch_size=2, verbose=2)
# Estimate model performancetrainScore = model.evaluate(trainX, trainY, verbose=0)print('Train Score: %.2f MSE (%.2f RMSE)' % (trainScore, math.sqrt(trainScore)))testScore = model.evaluate(testX, testY, verbose=0)print('Test Score: %.2f MSE (%.2f RMSE)' % (testScore, math.sqrt(testScore)))
Finally, we can generate predictions using the model for both the train and test dataset to get a visual indication of the skill of the model.
Because of how the dataset was prepared, we must shift the predictions so that they aline on the x-axis with the original dataset. Once prepared, the data is plotted, showing the original dataset in blue, the predictions for the train dataset in green the predictions on the unseen test dataset in red.
# generate predictions for trainingtrainPredict = model.predict(trainX)testPredict = model.predict(testX) # shift train predictions for plottingtrainPredictPlot = numpy.empty_like(dataset)trainPredictPlot[:, :] = numpy.nantrainPredictPlot[look_back:len(trainPredict)+look_back, :] = trainPredict # shift test predictions for plottingtestPredictPlot = numpy.empty_like(dataset)testPredictPlot[:, :] = numpy.nantestPredictPlot[len(trainPredict)+(look_back*2)+1:len(dataset)-1, :] = testPredict # plot baseline and predictionsplt.plot(dataset)plt.plot(trainPredictPlot)plt.plot(testPredictPlot)plt.show()
We can see that the model did a pretty poor job of fitting both the training and the test datasets. It basically predicted the same input value as the output.
# Multilayer Perceptron to Predict International Airline Passengers (t+1, given t)import numpyimport matplotlib.pyplot as pltimport pandasimport mathfrom keras.models import Sequentialfrom keras.layers import Dense# fix random seed for reproducibilitynumpy.random.seed(7)# load the datasetdataframe = pandas.read_csv('international-airline-passengers.csv', usecols=[1], engine='python', skipfooter=3)dataset = dataframe.valuesdataset = dataset.astype('float32')# split into train and test setstrain_size = int(len(dataset) * 0.67)test_size = len(dataset) - train_sizetrain, test = dataset[0:train_size,:], dataset[train_size:len(dataset),:]print(len(train), len(test))# convert an array of values into a dataset matrixdef create_dataset(dataset, look_back=1):dataX, dataY = [], []for i in range(len(dataset)-look_back-1):a = dataset[i:(i+look_back), 0]dataX.append(a)dataY.append(dataset[i + look_back, 0])return numpy.array(dataX), numpy.array(dataY)# reshape into X=t and Y=t+1look_back = 1trainX, trainY = create_dataset(train, look_back)testX, testY = create_dataset(test, look_back)# create and fit Multilayer Perceptron modelmodel = Sequential()model.add(Dense(8, input_dim=look_back, activation='relu'))model.add(Dense(1))model.compile(loss='mean_squared_error', optimizer='adam')model.fit(trainX, trainY, epochs=200, batch_size=2, verbose=2)# Estimate model performancetrainScore = model.evaluate(trainX, trainY, verbose=0)print('Train Score: %.2f MSE (%.2f RMSE)' % (trainScore, math.sqrt(trainScore)))testScore = model.evaluate(testX, testY, verbose=0)print('Test Score: %.2f MSE (%.2f RMSE)' % (testScore, math.sqrt(testScore)))# generate predictions for trainingtrainPredict = model.predict(trainX)testPredict = model.predict(testX)# shift train predictions for plottingtrainPredictPlot = numpy.empty_like(dataset)trainPredictPlot[:, :] = numpy.nantrainPredictPlot[look_back:len(trainPredict)+look_back, :] = trainPredict# shift test predictions for plottingtestPredictPlot = numpy.empty_like(dataset)testPredictPlot[:, :] = numpy.nantestPredictPlot[len(trainPredict)+(look_back*2)+1:len(dataset)-1, :] = testPredict# plot baseline and predictionsplt.plot(dataset)plt.plot(trainPredictPlot)plt.plot(testPredictPlot)plt.show()
Epoch 195/2000s - loss: 536.7014Epoch 196/2000s - loss: 555.4216Epoch 197/2000s - loss: 552.2841Epoch 198/2000s - loss: 541.2220Epoch 199/2000s - loss: 542.3288Epoch 200/2000s - loss: 534.2096Train Score: 532.59 MSE (23.08 RMSE)Test Score: 2358.07 MSE (48.56 RMSE)
Taking the square root of the performance estimates, we can see that the model has an average error of 23 passengers (in thousands) on the training dataset and 48 passengers (in thousands) on the test dataset.
We can also phrase the problem so that multiple recent time steps can be used to make the prediction for the next time step.
This is called the window method, and the size of the window is a parameter that can be tuned for each problem.
For example, given the current time (t) we want to predict the value at the next time in the sequence (t + 1), we can use the current time (t) as well as the two prior times (t-1 and t-2).
When phrased as a regression problem the input variables are t-2, t-1, t and the output variable is t+1.
The create_dataset() function we wrote in the previous section allows us to create this formulation of the time series problem by increasing the look_back argument from 1 to 3.
A sample of the dataset with this formulation looks as follows:
We can re-run the example in the previous section with the larger window size. We will increase the network capacity to handle the additional information. The first hidden layer is increased to 14 neurons and a second hidden layer is added with 8 neurons. The number of epochs is also increased to 400.
The whole code listing with just the window size change is listed below for completeness.
# Multilayer Perceptron to Predict International Airline Passengers (t+1, given t, t-1, t-2)import numpyimport matplotlib.pyplot as pltfrom pandas import read_csvimport mathfrom keras.models import Sequentialfrom keras.layers import Dense # convert an array of values into a dataset matrixdef create_dataset(dataset, look_back=1):dataX, dataY = [], []for i in range(len(dataset)-look_back-1):a = dataset[i:(i+look_back), 0]dataX.append(a)dataY.append(dataset[i + look_back, 0])return numpy.array(dataX), numpy.array(dataY) # fix random seed for reproducibilitynumpy.random.seed(7)# load the datasetdataframe = read_csv('international-airline-passengers.csv', usecols=[1], engine='python', skipfooter=3)dataset = dataframe.valuesdataset = dataset.astype('float32')# split into train and test setstrain_size = int(len(dataset) * 0.67)test_size = len(dataset) - train_sizetrain, test = dataset[0:train_size,:], dataset[train_size:len(dataset),:]# reshape datasetlook_back = 3trainX, trainY = create_dataset(train, look_back)testX, testY = create_dataset(test, look_back)# create and fit Multilayer Perceptron modelmodel = Sequential()model.add(Dense(12, input_dim=look_back, activation='relu'))model.add(Dense(8, activation='relu'))model.add(Dense(1))model.compile(loss='mean_squared_error', optimizer='adam')model.fit(trainX, trainY, epochs=400, batch_size=2, verbose=2)# Estimate model performancetrainScore = model.evaluate(trainX, trainY, verbose=0)print('Train Score: %.2f MSE (%.2f RMSE)' % (trainScore, math.sqrt(trainScore)))testScore = model.evaluate(testX, testY, verbose=0)print('Test Score: %.2f MSE (%.2f RMSE)' % (testScore, math.sqrt(testScore)))# generate predictions for trainingtrainPredict = model.predict(trainX)testPredict = model.predict(testX)# shift train predictions for plottingtrainPredictPlot = numpy.empty_like(dataset)trainPredictPlot[:, :] = numpy.nantrainPredictPlot[look_back:len(trainPredict)+look_back, :] = trainPredict# shift test predictions for plottingtestPredictPlot = numpy.empty_like(dataset)testPredictPlot[:, :] = numpy.nantestPredictPlot[len(trainPredict)+(look_back*2)+1:len(dataset)-1, :] = testPredict# plot baseline and predictionsplt.plot(dataset)plt.plot(trainPredictPlot)plt.plot(testPredictPlot)plt.show()
Epoch 395/4000s - loss: 485.3482Epoch 396/4000s - loss: 479.9485Epoch 397/4000s - loss: 497.2707Epoch 398/4000s - loss: 489.5670Epoch 399/4000s - loss: 490.8099Epoch 400/4000s - loss: 493.6544Train Score: 564.03 MSE (23.75 RMSE)Test Score: 2244.82 MSE (47.38 RMSE)
We can see that the error was not significantly reduced compared to that of the previous section.
Looking at the graph, we can see more structure in the predictions.
Again, the window size and the network architecture were not tuned, this is just a demonstration of how to frame a prediction problem.
Taking the square root of the performance scores we can see the average error on the training dataset was 23 passengers (in thousands per month) and the average error on the unseen test set was 47 passengers (in thousands per month).
Window Method For Time Series Predictions With Neural NetworksBlue=Whole Dataset, Green=Training, Red=Predictions
In this post, you discovered how to develop a neural network model for a time series prediction problem using the Keras deep learning library.
How to frame time series prediction problems as a regression problems and develop a neural network model.
How use the window approach to frame a time series prediction problem and develop a neural network model.
Do you have any questions about time series prediction with neural networks or about this post?
Ask your question in the comments below and I will do my best to answer.
Dr. Jason Brownlee is a husband, proud father, academic researcher, author, professional developer and a machine learning practitioner. He is dedicated to helping developers get started and get good at applied machine learning.
This is a new tool for me so an interesting post to get started!
It looks to me like your plot for the first method is wrong. As youre only giving the previous time point to predict the next, the model is going to fit (close to) a straight line and wont pull out the periodicity your plot suggests. The almost perfect fit of the red line to the blue line also doesnt reflect the much worse fit suggested in the model score!
In order to forecast t+2, t+3, t+n., is it recommended to use the previous prediction (t+1) as the assumed data point. 
For example, if I wanted to forecast t+2, I would use the available data including my prediction at t+1. 
I understand that the error would increase the further out the forecast due to relying on predictions as data points.
Yes, using this approach will provide multiple future data points. As you suggest, the further in the future you go, the more likely errors are to compound.
Give it a go, its good to experiment with these models and see what they are capable of.
Look forward to these time series forecast with multiple features examples  when do you expect to post them to your blog?
As always thx for this valuable resource and for sharing your experience !
Thank you for a great article. I have a big doubt and also related to the plot posted in the earlier comment which shows a sort of lag in the prediction. Here we are training the model on t to get predictions for t+1.
Given this I would assume that when the model sees an input of 112 it should predict around 118 (first data point in the training set). But thats not what the predictions show. Copying the top 5 train points and their subsequent predictions generated by the code given in this post for the first example:
I am trying to understand from a model perspective as to why is it predicting with a lag?
Just as Steve Buckley pointed out, your first method seems to be wrong. The model indeed just fits a straight line ( yPred = a*X+b) , which can be verified by calculating predictions on an input such as arange(200).
Because you shift the results afterwards before plotting, the outcome seems very good. However, from a conceptual point of view, it should be impossible to predict X_t+1 correctly based on only X_t, as the latter contains no trend or seasonal information. 
Here is what Ive got after trying to reproduce your results:
as you can see, the yPred is way off ( it should be equal to Y), but looks good when shifted one period.
I was just wondering if in function create_dataset, there should be range(len(dataset)-1) in the loop. Hence for plotting logic, it should be:
I am just in a big confusion with the index and getting somewhat difference plot for look_back=3 : http://imgur.com/a/DMbOU
Hey, thanks for a most helpful tutorial, any ideas why this seems to work better than the time series predictions using RNNs and LSTM in the sister tutorial? My intuition predicts the opposite.
Hey there! Great blog and articles  the examples really help a lot! Im new to this so excuse the stupid question if applicable  I want to predict the next three outputs based on the same input. Is that doable in the LSTM framework? This is for predicting the water temperature for the next 3 days.
This particular time-series has strong seasonality and looks exponential in trend. In reality, the growth rate of this time series is more important. Could you plot the year-on-year growth rate?
I agree with Steve Buckley. The code is predicting x[i+1] = x[i] (approximately), that why the last part of code, which is supposed to fix the shift, couldnt get the shift part right. 
Try the following: pick any point in your testX, say testX[i], use the model to predict testY[i], then instead of using testX[i+1], use testY[i] as the input parameter for model.predict(), and so on. You will end up with a nearly straight line.
Id thank you for your wonderful posts on neural network, which helped me a lot when learning neural network. However, this particular code is not correct.
Thanks for great article! It is really helpful for me. I have one question. If I have two more variable, how can i do? Take example, my data looks like follow,
I have one question like Jeremys. Is there any suggestion for me if I want to predict 2 variables? Data frame shown as below:
I want to predict Y1 and Y2. Also, Y1 and Y2 have some correlations.
Yes, this is often called a sequence prediction problem in deep learning or a multi-step prediction problem in time series prediction.
You can use an LSTM with two outputs or you can use an MLP with two outputs to model this problem. Be sure to prepare your data into this form.
My feature vectors/predictors are Date, Time, Power1, Power2, Power3, Meter1. i am trying to predict Meter 2. 
I would like to instead of using MLP use RNN/LSTM for the above time series prediction.
Can you pl. suggest is this is possible? and if yes, any pointers would help
I have one question : it would be usefull to have similar stuff on live data. let s say I have access to some real time data (software downloads, stock price ) , would it requires to train the model each time new data is available ?
I agree nicoad, a real-time example would be great. Ill look into it.
A great thing about neural networks is that they can be updated with new data and do not have to be re-trained from scratch.
Hi,your original post code is to use 1(or 3) dimension X to predict the later 1 dimension Y.how about I want to use 48 dimension X to predict 49th and 50th.what i mean is i increase the time unit i want to predict ,predict 3 or even 10 time unit . under such condition : does that mean i just change the output_dime of the last output layer :
the list inside [ 128.6,127.5 ] [121,2,122,3] does not like t+1 and t+2.
What i means is [128.6,127.5] doesnt mean t+1 and t+2 prediction, it most possibly mean 2 possible prediction for t+1.
one output cell with 2dimension and 2 output cell with 1 dimension is different.
It seems i should use seq2seq or use timedistributed wrapper .
I stilll explored this and have not got one solution .
hi jason , I made a experiment on the jupyter notebook and published on the github .The code could output 2 columns data.
However! If you look very carefully of the trainPredict data(IN[18] of the notebook).
the list inside [ 128.6,127.5 ] [121,2,122,3] does not like t+1 and t+2.
What i means is [128.6,127.5] doesnt mean t+1 and t+2 prediction, it most possibly mean 2 possible prediction for t+1.
1 output cell with 2 dimension and 2 output cell with 1 dimension is different.
The input dimension and the output dimension will be tricky for the NN.
Thanks Jason for the conceptual explaining. I have one question about the KERAS package: 
It looks you input the raw data (x=118 etc) to KERAS. Do you know whether KERAS needs to standardize (normalize) the data to (0,1) or (-1,1) or some distribution with mean of 0?
I am trying to build a NN for Time-Series-Prediction. But my Datas are different than yours.
I want to predict a whole next day. But a whole day is defined as 48 values.
There is a value for each half an hour of a whole day. 
i want to predict the values for every half an hour for the next few days. How could this work?
Why doesnt need the reLu Activation function that the input datas are normalized between 0 and 1?
If i use the sigmoid activation function, there is a must, that the input datas are normalized.
Generally, because of the bounds of the sigmoid function imposes hard limits values outside of 0-1. 
The Rectifier function is quite different, you can read up on it here:
Id recommend implementing in excel or Python and having a play with inputs and outputs.
But why has your Output Layer no activition Function? Is there a default activition function which keras uses if you give one as parameter? if yes, which is it? if no, why is it possible to have a Layer without a activition function in it?
Suppose I have a dataset with two fields: date (timestamp), amount (float32) describing a year.
on the first day of each month the amount is set to -200.
This is true for 11 months, except for the 12th (December).
Is there a way to train a NN so that it returns 12, marking the December as not having such and amount on its first day?
Is it common to only predict the single next time point? Or are there times/ways to predict 2,3, and 4 times points into the future, and if so, how do you assess performance metrics for those predictions?
The forecast time horizon is problem specific. You can predict multiple steps with a MLP or LSTM using multiple neurons in the output layer.
Evaluation is problem specific but could be RMSE across the entire forecast or per forecast lead time.
Relu in hidden because it works really well. Sigmoid for binary outputs, linear for regression outputs, softmax for muti-class classification. 
Often you can transform your data for the bounds of a given activation function (e.g. 0,1 for sigmoid, -1,1 for tanh, etc.)
I always have a question, if we only predict 1 time step further (t+1), the accurate predicted result is just copy the value of t, as the first figure shows. When we add more input like (t-2, t-1, t), the predicted result get worse. Even compare with other prediction method like ARIMA, RNN, this conclusion perhaps is still correct. To better exhibit the power of these prediction methods, should we try to predict more time steps further t+2, t+3, ? 
Thanks for sharing your information here. Anyway i was not able to reproduce your last figure. On my machine it still looks like the bad figure. 
I used the code as stated above. Where is my missunderstanding here?
Firstly thanks Jason, I try MLP and LSTM based models on my time series data, and I get some RMSE values. ( e.g. train rmse 10, and test 11) (my example count 1400, min value:21, max value 210 ) What is acceptance value of RMSE. ?
Is it possible to make a DNN with several outputs? For example the output layer has several neurons responsible for different flight directions. What difficulties can arise?
Hello, Jason, i am a student, recently i am learning from your blog. Could you make a display deep learning model training history in this article? I will be very appreciated if you can, because i am a newer. Thank you!
Does anybody have an idea/code snippet how to store observations of this example code in a variable, so that the variable can be used to to make predictions beyond the airline dataset (one step in the future)?
Fit your model on all available data. When a new observation arrives, scale it appropriately, gather it with the other lag observations your model requires as input and call model.predict().
After several days I manged to make a prediction on unseen data in this example (code below).
How many observations should be used to get a good prediction on unseen data.
Are there standard tools available to measure corresponding performances and suggest the amount of observations?
Would this topic the same as choosing the right window-size for time-series analysis, or where would be the difference?
The number of obs required depends on how you have configured your model.
The best window size for a given problem is unknown, you must discover it through trial and error, see this post:
Is there a method or trial and error-strategy to find out how many lag observations are best for a forecast of unseen data?
Is there a relation between look_back (window size) and lag observations?
In theory I could use all observations to predict one step of unseen data. Would this be useful?
You can use ACF and PACF plots to discover the most relevant lag obs:
The promise of LSTMs is that they can learn the appropriate time dependence structure without having it explicitly specified.
If I fill the model with 3 obs, I get 3 predictions/data points of unseen data. 
If I only want to predict one step in the future, should I build an average of the resulting 3 predictions,
or should I simply use the last of the 3 prediction steps?
With obsv(n) = float(testPredict[n]) I took predictions of the test dataset as observations.
Instead we take a partition of the original raw data as x/observations to predict unseen data, with a trained/fitted model- IN EVERY CASE.
This is Arman from Malaysia. I am a student of Multimedia University. I want to do “Self-Tuning performance of Hadoop using Deep Learning”. So which framework I will consider for this sort of problem. as like DBM, DBN , CNN, RNN ?
My raw data items have a decent date column. Is this what you meant?
I have everything parameterized in a central batch file now (pipeline).
and build the variable EXPECTED in the context of this script.
Unfortunately I dont know how to do it right. Im a little bit frustrated at this point.
for i in range(len(test)): <-- what should I better use here?
expected = dataset[len(train) + i + 1] <-- what should I better use here?
This looks cool so far, could I use the index to retrieve a var called EXPECTED?
This is a great example that machine learning is often much more than knowing how to use the algorithms / libraries. Its always important to understand the data we are working with. For this example as it is 1 dimensional this is luckily quite easily done.
In the first example we are giving the the algorithm one previous value and ask it What will the next value be?. 
Since we use a neural net not taking into account any time behavior, this system is strongly overdetermined. There are a lot of values at the y value 290 for example. For half of them the values decline, for half of them the values increase. If we dont give the algorithm any indication, how should it know which direction this would be for the test datapoint? There is just not enough information. 
One idea could be to additionally give the algorithm the gradient which would help in the decision whether we a rising or a falling value follows (which is somehow what we do when adding a lookback of 2). Yet, the results do obviously not improve significantly.
Here I want to come back to understand the data you are dealing with. If we look at the plot, there are two characteristics which are obvious. A generally rising trend and a periodicity. We want the algorithm to cover both. Only then, will the prediction be accurate. We see that there is an obvious 12 month periodicity (think of summer vacation, christmas). If we want the algorithm to cover that periodicity without including model knowledge (as we are using an ANN) we have to at least provide it the data in a format to deduct this property.
Hence: Extending the lookback to 12 month (12 datapoints in the X) will lead to a significantly improved 1 month ahead-prediction! Now however, we have a higher feature dimension, which might not be desired due to computational reasons (doesnt matter for this toy example, but anyway). Next thing we do is take only 3 month steps at lookback (still look back 12 month but skip 2 months in the data). We still cover the periodicity but reduce the feature amount. The algorithm provides almost the same performance for the 1 month ahead prediction.
Another possibility would surely be to add the month (Jan, Feb, etc.) as a categorical feature.
Hello Jason! Thanks for the great example! I was looking for this kind of example.
Im learning Neural Network these days and trying to predict the number which is temperature like this example, but I have more inputs to predict temperature.
Then should I edit on the pandas.read.csv(,usecols[1],) to usecols[0:4] if I have 5 inputs?
Hey, I am trying to make a case where the test case is not given but the model should predict the so called future of the timeseries. Hence, I wrote a code which takes the last row of the train data and predict a value from it then put the predicted value at the end of that row and make a prediction again. After doing this procedure for let say len(testX) times. It ended up like an exponential graph. I can upload it if you want to check it out. My code is given below. I dont understand why it works like that. I hope you can enlighten me.
 new_=create_pred(new_,testPredict[0][0]) #this code does if new_ is [1,2,3] and testPredict[0][0] is 4 the output is [2,3,4]
Its awesome article. Very Helpful. I implemented these concepts in my Categorical TIme Series Forecasting problem.But the result I got is very unexpected.
My TIme Series can take only 10 values from 0 to 9. Ive approx 15k rows of data.I want to predict next value in the time series. 
But the issue is 1 appears in time series most of the time. So starting from 2nd or 3rd epoch LSTM predicts only 1 for whatsoever input. I tried varying Hyperparameter but its not working out. Can you please point out what could be the approach to solve the problem?

You can learn a lot about neural networks and deep learning models by observing their performance over time during training.
Keras is a powerful library in Python that provides a clean interface for creating deep learning models and wraps the more technical TensorFlow and Theano backends.
In this post you will discover how you can review and visualize the performance of deep learning models over time during training in Python with Keras.
Update Mar/2017: Updated example for Keras 2.0.2, TensorFlow 1.0.1 and Theano 0.9.0.
Display Deep Learning Model Training History in KerasPhoto by Gordon Robertson, some rights reserved.
Keras provides the capability to register callbacks when training a deep learning model.
One of the default callbacks that is registered when training all deep learning models is the History callback. It records training metrics for each epoch. This includes the loss and the accuracy (for classification problems) as well as the loss and accuracy for the validation dataset, if one is set.
The history object is returned from calls to the fit() function used to train the model. Metrics are stored in a dictionary in the history member of the object returned.
For example, you can list the metrics collected in a history object using the following snippet of code after a model is trained:
Whether the model may have already converged (plateau of the line).
Whether the mode may be over-learning the training data (inflection for validation line).
Take my free 2-week email course and discover MLPs, CNNs and LSTMs (with sample code).
Click to sign-up now and also get a free PDF Ebook version of the course.
In the example below we create a small network to model the Pima Indians onset of diabetes binary classification problem. This is a small dataset available from the UCI Machine Learning Repository. You can download the dataset and save it as pima-indians-diabetes.csv in your current working directory.
The example collects the history, returned from training the model and creates two charts:
A plot of accuracy on the training and validation datasets over training epochs.
A plot of loss on the training and validation datasets over training epochs.
# Visualize training historyfrom keras.models import Sequentialfrom keras.layers import Denseimport matplotlib.pyplot as pltimport numpy# fix random seed for reproducibilityseed = 7numpy.random.seed(seed)# load pima indians datasetdataset = numpy.loadtxt("pima-indians-diabetes.csv", delimiter=",")# split into input (X) and output (Y) variablesX = dataset[:,0:8]Y = dataset[:,8]# create modelmodel = Sequential()model.add(Dense(12, input_dim=8, kernel_initializer='uniform', activation='relu'))model.add(Dense(8, kernel_initializer='uniform', activation='relu'))model.add(Dense(1, kernel_initializer='uniform', activation='sigmoid'))# Compile modelmodel.compile(loss='binary_crossentropy', optimizer='adam', metrics=['accuracy'])# Fit the modelhistory = model.fit(X, Y, validation_split=0.33, epochs=150, batch_size=10, verbose=0)# list all data in historyprint(history.history.keys())# summarize history for accuracyplt.plot(history.history['acc'])plt.plot(history.history['val_acc'])plt.title('model accuracy')plt.ylabel('accuracy')plt.xlabel('epoch')plt.legend(['train', 'test'], loc='upper left')plt.show()# summarize history for lossplt.plot(history.history['loss'])plt.plot(history.history['val_loss'])plt.title('model loss')plt.ylabel('loss')plt.xlabel('epoch')plt.legend(['train', 'test'], loc='upper left')plt.show()
The plots are provided below. The history for the validation dataset is labeled test by convention as it is indeed a test dataset for the model.
From the plot of accuracy we can see that the model could probably be trained a little more as the trend for accuracy on both datasets is still rising for the last few epochs. We can also see that the model has not yet over-learned the training dataset, showing comparable skill on both datasets.
From the plot of loss, we can see that the model has comparable performance on both train and validation datasets (labeled test). If these parallel plots start to depart consistently, it might be a sign toÂ stop training at an earlier epoch.
In this post you discovered the importance of collecting and reviewing metrics during the training of your deep learning models.
You learned about the History callback in Keras and how it is always returned from calls to the fit() function to train your models. You learned how to create plots from the history data collected during training.
Do you have any questions about model training history or about this post? Ask your question in the comments and I will do my best to answer.
Dr. Jason Brownlee is a husband, proud father, academic researcher, author, professional developer and a machine learning practitioner. He is dedicated to helping developers get started and get good at applied machine learning.
Great tutorial and very articulate around how each of the network in keras works.
does keras support this kind of dataset for implementing an autoencoder rather than a FFN ?
Keras does support autoencoders, but I dont use them generally as they are been surpassed by big MLPs and specialized methods like LSTMs and CNNs that can learn features while training.
When dropout is applied, I wonder how the loss and acc values are computed. After each epoch, does the program still drop the neurons/weights to compute the loss and accuracy, or use the whole network?
Id like to be able to plot the history of a stateful LSTM. Ive tried something like the below, but in this case its failing b/c Im asking python dicts to do something they dont like (Im new to python). Ive tried some other approaches which have all failed for python-related reasons. 
Reprinting your .fit() code from your stateful tutorial (and adding a failed attempt at capturing history):
Consider using a list and appending the history object to the list. Also consider just creating an all new model each iteration to try and keep it all apples to apples comparison.
I would like to visualize loss and accuracy graphs per each epoch during training.
I was thinking of doing so by writing a callback but wasnt sure exactly how and if this can be done.
Hi Aviel, Keras is not designed to do this natively. 
Maybe use a callback to post to a file/db and use a separate process to plot? 
I would suggest getting something ghetto like that going and see how it looks.
I have a quick question. I want to plot the graphs but my computing resources are **not** local. Is there a way to have a callback or something that stored each error value in a CSV file and later plot it? Or is there a way idk to save history object, maybe pickle it and then send to my local computer with some standard tool, like rsync or dropbox?
What do you recommend for these remote plotting experiments? I just need to get the data somewhere I can plot the error/loss vs epochs.
(also, can I plot vs iterations instead of epochs? just curious)
I have a very simple question and I hope you dont mind me asking, I want to save loss function figure with plt.savefig(figure), but I get module is not callable error, and if I comment out plt.savefig(figure) everything works just fine. Do you happen to have any idea why?
I solved the error, thanks! I have an another issue however, Im doing a grid search on parameters (epoch and batch size) and for each combination I plot the loss function. However, for each combination it just keeps displaying each results on top each other in the same figure! Any idea why that might happen?
Quick question. I am using tensorflow without Keras at the moment, and am plotting the loss and accuracy of a CNN. I am using cross entropy with adam optimizer, and using the cross entropy value as the loss. Is this right?
Also, if the loss is in the 200-300 range, should I be plotting the log value of this? as all the graphs I see the loss is between 0-1.
I am running this example from your book, but I am using cross_validation in particular StratifiedKFold. So when I fit the model I do not pass a validation_split or validation_data hence my model history has only keys [acc, loss]. I am using model.evaluate(). How can I visualize the test ?
1) when setting verbose to 2, i expect printing during each epoc including progressing bar, but i see only the train and validation loss (without seeing the accuracy or progressing bar) 
2) when the run reaches the part of trying to plot, i receive an error:
That is correct, if you want a progress bar set verbose=1.
You must add the accuracy metric to the fit function. The error suggests this was not done. Learn more about metrics here:
Hi Jason, thanks a lot, I still have a few more questions:
a. How can I plot the ROC curve using history object?
b. How can I save best model after each epoch? (overwrite my model with a new one only if the accuracy over the validation set has improved) 
I do not have an example of plotting the ROC curve with Keras results.
Hi Jeson, I am using more than 100 gb dataset for building a model. where i am using HDF5 data base for data loading.so for this type of configuration I am manually iterate the training process. So as I am using manual itteration, History file is not appending the model information, instade of history file is creating after every epoc. How to update history file as it append in normal process.
can I manually append the model information after every epoch.as history file information is needed for model optimization.
Hi Jason, I wrote a LSTM model to train my brain MRI slices. For my dataset, each patient has 50 slices, and n patients are divided into training and validation sets . My LSTM model is designed as below:
 model.add(LSTM(128, input_shape = (max_timesteps, num_clusters), activation=tanh, recurrent_activation=elu, return_sequences = False, stateful = False, name=lstm_layer))
 model.fit(X_train, y_train, validation_data=(X_vald, y_vald), epochs = epoch_num, batch_size = batch_size, shuffle = True)
First, I use the GlobalAveragePooling layer of fine-tuned GoogLeNet to extract the feature of each slice.
Second, the n1*50*2048 features from training set and n2*50*2048 features from validation set are used to train my LSTM model.
However, the training process is very wired. The accuracy of training and validation decreases suddenly at Epoch 46. Could you give some advise about this results? The process of Epoch 40 to 50 is attached:
407/407 [==============================]  25s  loss: 8.6558e-05  acc: 1.0000  val_loss: 1.3870  val_acc: 0.8512
407/407 [==============================]  25s  loss: 1.7462e-06  acc: 1.0000  val_loss: 1.2368  val_acc: 0.8595
407/407 [==============================]  25s  loss: 4.5732e-06  acc: 1.0000  val_loss: 1.1689  val_acc: 0.8760
407/407 [==============================]  25s  loss: 6.2214e-07  acc: 1.0000  val_loss: 1.2545  val_acc: 0.8760
407/407 [==============================]  25s  loss: 2.5658e-07  acc: 1.0000  val_loss: 1.2440  val_acc: 0.8595
407/407 [==============================]  25s  loss: 6.2594e-07  acc: 1.0000  val_loss: 1.2281  val_acc: 0.8678
407/407 [==============================]  25s  loss: 3.3054e-07  acc: 0.5676  val_loss: 1.1921e-07  val_acc: 0.5372
407/407 [==============================]  25s  loss: 1.1921e-07  acc: 0.5061  val_loss: 1.1921e-07  val_acc: 0.5372
407/407 [==============================]  25s  loss: 1.1921e-07  acc: 0.5061  val_loss: 1.1921e-07  val_acc: 0.5372
407/407 [==============================]  25s  loss: 1.1921e-07  acc: 0.5061  val_loss: 1.1921e-07  val_acc: 0.5372
407/407 [==============================]  25s  loss: 1.1921e-07  acc: 0.5061  val_loss: 1.1921e-07  val_acc: 0.5372
Im attempting to use it right now however for some reason it is decreasing my accuracy when I implement it. When I comment the callback out, the accuracy increases by 30%. Whats going on here? Should I just stick to your method instead of using the Tensorboard?
Thanks for your nice tutorial. I have two questions needed you to make it clear:
1. How can avoid from history object returned by compile function printed.

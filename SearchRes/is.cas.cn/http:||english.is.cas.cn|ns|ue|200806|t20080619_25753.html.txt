http://english.is.cas.cn/ns/ue/200806/t20080619_25753.html
In December 2006, we published "The Berkeley View", a broad survey of the issues for the whole field concerning the multicore/manycore sea change. We view the ultimate goal as the ability to productively create efficient and correct software that scales smoothly as the number of cores per chip doubles biennially. This talk covers the specific research agenda that a large group of us at Berkeley is following as part of the newly formed Parallel Computing Laboratory. To take a fresh approach to the longstanding parallel computing problem, our research agenda is driven by compelling applications developed by domain experts. Historically, past efforts to resolve these challenges have often been driven "bottom-up" from the hardware, with applications an afterthought. We are focusing on exciting new applications that need much more computing horsepower to run well, rather than on legacy programs that already run well on todays computers. Our applications are in the areas of personal health, image retrieval, music, etc. The development of parallel software is the heart of our research agenda. The task will be divided into two layers: an efficiency layer that aims at low overhead for 10 percent of the best programmers, and a productivity layer for the rest of the programming community--including domain experts--that reuses the parallel software developed at the efficiency layer. Key to this approach is a layer of libraries and programming frameworks centered on the 13 computational bottlenecks ("dwarfs") that we identified in the original Berkeley View report. We will also create a Composition and Coordination Language to make it easier to compose these components. Finally, we will rely on autotuning to map the software efficiently to a particular parallel computer. Past attempts have often relied on a single programming abstraction and language for all programmers and on automatically parallelizing compilers, whereas we believe most future applications will be built from libraries of components written in multiple languages. The role of the operating system and the architecture in this project is to support software and applications in achieving the ultimate goal, rather than the conventional approach of fixing the environment in which parallel software must survive. Example innovations include very thin hypervisors, which allow user-level control of processor scheduling, and hardware support for partitioning and fast barrier synchronization. We will prototype the hardware of the future using FPGA, which we believe are fast enough to be interesting to parallel software researchers yet flexible enough to "tape out" new designs every day while being cheap enough that university researchers can afford to construct systems containing hundreds of processors. This prototyping infrastructure is called RAMP, and is being developed by a consortium of universities and companies. The primary funding for the Par Lab is from Intel, Microsoft, and the State of California. 
Dr. Krste Asanovi recently returned to the University of California at Berkeley as an Associate Professor in the Computer Science Division beginning July 1, 2007. He received his PhD from Berkeley in 1998 and subsequently joined the MIT faculty, where he earned an NSF CAREER Award in 2001 and tenure in 2005. At UCB, he is one of the founders of the new Parallel Computing Laboratory (ParLab, http://parlab.eecs.berkeley.edu/), which is reinventing the computing system stack for future manycore computers. 
